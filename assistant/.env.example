# ============================================================
# MindHome Assistant — Konfiguration
# Kopiere diese Datei nach .env und passe die Werte an:
#   cp .env.example .env
#   nano .env
# ============================================================

# --- Home Assistant Verbindung (MUSS angepasst werden) ---
HA_URL=http://192.168.1.100:8123
HA_TOKEN=dein_long_lived_access_token_hier

# --- MindHome Add-on Verbindung ---
# Standard: Ingress-Port 5000, extern ggf. via Port-Mapping (z.B. 8099)
MINDHOME_URL=http://192.168.1.100:8099

# --- Daten-Verzeichnis ---
# Dual-SSD Setup:  DATA_DIR=/mnt/data   (SSD 2 fuer ChromaDB, Redis, Uploads)
# Single-SSD:      DATA_DIR=./data      (alles lokal)
DATA_DIR=/mnt/data

# --- Ollama (laeuft nativ auf dem Host, nicht aendern) ---
OLLAMA_URL=http://host.docker.internal:11434

# --- Modelle (3-Stufen: fast/smart/deep) ---
# MODEL_FAST=qwen3:4b
# MODEL_SMART=qwen3:14b
# MODEL_DEEP=qwen3:32b

# --- Datenbanken (Docker-intern, nicht aendern) ---
REDIS_URL=redis://redis:6379
CHROMA_URL=http://chromadb:8000

# --- Benutzer ---
USER_NAME=Max
ASSISTANT_NAME=Jarvis

# --- Server (nicht aendern) ---
ASSISTANT_HOST=0.0.0.0
ASSISTANT_PORT=8200

# --- API Key (wird auto-generiert wenn leer) ---
# ASSISTANT_API_KEY=

# --- Speech Services (Whisper STT + Piper TTS) ---
# Whisper (STT): Spracherkennung via Wyoming Protocol
SPEECH_DEVICE=cpu                    # "cpu" (Phase 1) oder "cuda" (Phase 2 mit GPU)
WHISPER_MODEL=small-int8             # CPU: small-int8 oder medium-int8 | GPU: large-v3-turbo
WHISPER_LANGUAGE=de                  # Sprache fuer Transkription
WHISPER_BEAM_SIZE=5                  # Beam Search Breite (hoeher = genauer, langsamer)
WHISPER_COMPUTE=int8                 # CPU: int8 | GPU: float16

# Piper (TTS): Sprachausgabe via Wyoming Protocol
PIPER_VOICE=de_DE-thorsten-high     # Deutsche Stimme (thorsten-high = beste Qualitaet)

# GPU-Modus aktivieren (Phase 2 — RTX 3090 Ti):
# Auskommentieren wenn GPU vorhanden + NVIDIA Container Toolkit installiert
# COMPOSE_FILE=docker-compose.yml:docker-compose.gpu.yml
