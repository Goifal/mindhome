# MindHome â€” JARVIS Masterplan
# "Von Smart Assistant zu echtem Jarvis"

> **Stand:** 2026-02-18
> **Aktueller Status:** v0.8.4 (Phase 5 abgeschlossen, Build 87)
> **Architektur:** PC 1 (HAOS Add-on v0.8.4) + PC 2 (Assistant Server)
> **Prinzip:** 100% lokal, kein Cloud, Privacy-first
> **GRUNDREGEL: Jarvis hat KEINEN Internetzugang.**

---

## Offline-Prinzip (Eiserne Regel)

Jarvis laeuft ohne Internet. Sobald das System steht, wird der Internetzugang gekappt.

**Was das bedeutet:**
- Jarvis macht KEINE eigenen HTTP-Calls ins Internet. Niemals.
- Alle externen Daten (Wetter, Pollen, Kalender) kommen ueber **Home Assistant Entities**.
  HA holt die Daten â†’ exponiert sie als Entities â†’ Jarvis liest die Entities lokal.
- Alle Modelle (LLM, STT, TTS, Vision) laufen lokal via Ollama/Piper/Whisper.
- Alle Datenbanken (ChromaDB, Redis) laufen lokal.
- Sound-Dateien sind lokal gespeichert, kein Streaming.
- Frontend-Libraries (React, Babel) werden beim Docker-Build einmalig heruntergeladen
  und danach ins Image gebacken â€” zur Laufzeit kein CDN-Zugriff.

**Erlaubte Netzwerk-Kommunikation (nur lokal):**
| Service | URL | Zweck |
|---------|-----|-------|
| Home Assistant | `http://supervisor/core` | Smart-Home Steuerung + Entities |
| Ollama | `http://localhost:11434` | LLM (Qwen) |
| ChromaDB | `http://localhost:8100` | Semantic Memory |
| Redis | `redis://localhost:6379` | Cache, Queues, State |
| Assistant | `http://192.168.1.100:8200` | MindHome Assistant Server |

**Code-Audit (2026-02-18): Bestanden.** Keine externen Internet-Calls im bestehenden Code.

---

## Architektur-Ãœbersicht

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PC 1 â€” Home Assistant OS     â”‚     â”‚  PC 2 â€” Assistant Server      â”‚
â”‚                               â”‚     â”‚                               â”‚
â”‚  MindHome Add-on (v0.8.4)    â”‚     â”‚  MindHome Assistant           â”‚
â”‚  â”œâ”€ 23 Domain-Plugins        â”‚â—„â”€â”€â”€â–ºâ”‚  â”œâ”€ brain.py (Orchestrator)   â”‚
â”‚  â”œâ”€ Pattern Engine            â”‚ API â”‚  â”œâ”€ personality.py            â”‚
â”‚  â”œâ”€ Automation Engine         â”‚     â”‚  â”œâ”€ mood_detector.py          â”‚
â”‚  â”œâ”€ Phase 4 Engines (10)     â”‚     â”‚  â”œâ”€ memory.py (3 Schichten)   â”‚
â”‚  â”œâ”€ Phase 5 Engines (7)      â”‚     â”‚  â”œâ”€ function_calling.py       â”‚
â”‚  â”œâ”€ 17 Route-Module          â”‚     â”‚  â”œâ”€ action_planner.py         â”‚
â”‚  â”œâ”€ 71 DB-Modelle            â”‚     â”‚  â”œâ”€ proactive.py              â”‚
â”‚  â””â”€ React Frontend           â”‚     â”‚  â”œâ”€ feedback.py               â”‚
â”‚                               â”‚     â”‚  â”œâ”€ autonomy.py (5 Level)    â”‚
â”‚  FERTIG â€” ~156 Features       â”‚     â”‚  â”œâ”€ activity.py              â”‚
â”‚                               â”‚     â”‚  â”œâ”€ summarizer.py            â”‚
â”‚                               â”‚     â”‚  â”œâ”€ context_builder.py       â”‚
â”‚                               â”‚     â”‚  â””â”€ model_router.py          â”‚
â”‚                               â”‚     â”‚                               â”‚
â”‚                               â”‚     â”‚  Ollama: Qwen 2.5 (3B + 14B) â”‚
â”‚                               â”‚     â”‚  ChromaDB + Redis             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Wichtig:** Das Add-on ist **fertig** (Phase 1â€“5 implementiert). Der Masterplan
fokussiert sich auf den **Assistant** â€” dort passiert die Jarvis-Transformation.

---

## Was der Assistant BEREITS kann

| Feature | Modul | Status |
|---------|-------|--------|
| Butler-PersÃ¶nlichkeit (5 Layer) | `personality.py` | âœ… |
| Stimmungserkennung (5 ZustÃ¤nde) | `mood_detector.py` | âœ… |
| 3-Schicht-GedÃ¤chtnis | `memory.py` + `semantic_memory.py` | âœ… |
| Fakten-Extraktion aus GesprÃ¤chen | `memory_extractor.py` | âœ… |
| 10 HA-Tools (Licht, Klima, Szenen...) | `function_calling.py` | âœ… |
| Multi-Step Action Planning | `action_planner.py` | âœ… |
| Proaktive Nachrichten (Alarm, Ankunft) | `proactive.py` | âœ… |
| Adaptives Feedback-Learning | `feedback.py` | âœ… |
| 5 Autonomie-Level | `autonomy.py` | âœ… |
| AktivitÃ¤tserkennung + Stille-Matrix | `activity.py` | âœ… |
| Zusammenfassungen (Tag/Woche/Monat) | `summarizer.py` | âœ… |
| Kontext-Builder (Haus-Status) | `context_builder.py` | âœ… |
| Smart Model Routing (3B/14B) | `model_router.py` | âœ… |
| Ankunfts-Briefing | `proactive.py` | âœ… |
| Mood-adaptive AntwortlÃ¤nge | `personality.py` | âœ… |

---

## Was der Assistant NOCH NICHT kann â€” Die Jarvis-LÃ¼cken

Aus unserer 47-Feature-Liste sind folgende **wirklich neu**:

| # | Feature | Warum fehlt es? |
|---|---------|----------------|
| 1 | Sarkasmus & Humor-Level | PersÃ¶nlichkeit ist statisch, kein konfigurierbarer Humor |
| 2 | Easter Eggs | Keine versteckten Befehle/Reaktionen |
| 3 | Selbstironie | Kein Selbst-Bewusstsein Ã¼ber eigene Situation |
| 4 | ZeitgefÃ¼hl | Keine Duration-Ãœberwachung laufender GerÃ¤te |
| 5 | Antwort-Varianz | BestÃ¤tigungen wiederholen sich |
| 6 | Running Gags | Keine Referenzen zu frÃ¼heren GesprÃ¤chen als Humor |
| 7 | Charakter-Entwicklung | PersÃ¶nlichkeit Ã¤ndert sich nicht Ã¼ber Wochen |
| 8 | Morning Briefing (strukturiert) | Ankunfts-Report existiert, aber kein Morgen-Briefing |
| 9 | Gute-Nacht-Routine | Kein strukturierter Tagesabschluss |
| 10 | Kontextuelle BegrÃ¼ÃŸung | BegrÃ¼ÃŸungen sind nicht tageszeit-/kontext-spezifisch |
| 11 | Abschied/Willkommen | Kein explizites Gehen/Kommen-Verhalten |
| 12 | Szenen-Intelligenz | "Mir ist kalt" â†’ wird nicht verstanden |
| 13 | GÃ¤ste-Modus | Kein Verhaltens-Wechsel bei GÃ¤sten |
| 14 | Raum-Intelligenz | RÃ¤ume haben keine Profile/PersÃ¶nlichkeit |
| 15 | Vorausschauendes Energie-Mgmt | Keine proaktiven Energie-VorschlÃ¤ge |
| 16 | Abwesenheits-Zusammenfassung | Kein Report "wÃ¤hrend du weg warst" |
| 17 | Saisonale Routine-Anpassung | Routinen Ã¤ndern sich nicht mit Jahreszeit |
| 18 | Anticipatory Actions | Muster werden nicht zu VorschlÃ¤gen |
| 19 | Explizites Wissens-Notizbuch | "Merk dir X" funktioniert nicht gezielt |
| 20 | Wissensabfragen | "Wie lang kocht ein Ei?" â†’ kein Routing |
| 21 | "Was wÃ¤re wenn" Simulation | Keine Szenario-Durchspielung |
| 22 | Intent-Extraktion aktiv | PlÃ¤ne aus GesprÃ¤chen werden nicht verfolgt |
| 23 | Langzeit-PersÃ¶nlichkeitsanpassung | Kein Formality-Score-Absinken Ã¼ber Zeit |
| 24 | Stimme & Sprechweise (SSML) | TTS ohne Betonung/Pausen |
| 25 | Sound-Design | Keine akustische IdentitÃ¤t |
| 26 | FlÃ¼ster-Modus | Keine automatische LautstÃ¤rke-Anpassung |
| 27 | Narration-Modus | Keine flieÃŸenden ÃœbergÃ¤nge/Sequenzen |
| 28 | Stimmungserkennung Sprachanalyse | Nur Text, nicht Audio |
| 29 | Personen-Erkennung Stimme | Kein Speaker Recognition |
| 30 | Multi-Room Presence | TTS geht nicht gezielt in einen Raum |
| 31 | Delegieren an Personen | "Sag Lisa..." funktioniert nicht |
| 32 | Vertrauensstufen | Keine Berechtigungslevel pro Person |
| 33 | Selbst-Diagnostik | Kein "Sensor XY ist offline"-Meldung |

**Das sind 33 wirklich neue Features fÃ¼r den Assistant.**

---

## Die Phasen: Nur Assistant-Features

```
Phase 1-5    âœ…  Add-on FERTIG (156 Features)
Assistant    âœ…  Basis FERTIG (14 Module, voll funktional)
     â”‚
Phase 6      âœ…  Jarvis PersÃ¶nlichkeit (10 Features â€” v0.9.0-v0.9.4)
     â”‚
Phase 7      âœ…  Jarvis Routinen & Tagesstruktur (9 Features â€” v0.9.5-v0.9.6)
     â”‚
Phase 8      âœ…  Jarvis GedÃ¤chtnis & Vorausdenken (7 Features â€” v0.9.7-v0.9.8)
     â”‚
Phase 9      âœ…  Jarvis Stimme & Akustik (6 Features â€” v0.9.9-v1.0.0)
     â”‚
Phase 10     ðŸ†•  Jarvis Multi-Room & Kommunikation (5 Features â€” Assistant + Add-on)
     â”‚
Phase 11     âœ…  Jarvis Wissen & Kontext (4 Features â€” RAG, Kalender, Korrekturen)
     â”‚
Phase 12     ðŸ”§  Jarvis Authentizitaet (5 Techniken â€” LLM Character Deepening)
     â”‚
Phase 13     ðŸ“‹  Jarvis Selbstprogrammierung (4 Stufen â€” Self-Evolving Assistant)
     â”‚
Phase 14     ðŸ“‹  Jarvis Wahrnehmung & Sinne (3 Features â€” Vision, Multi-Modal, Ambient)
     â”‚
Phase 15     ðŸ“‹  Jarvis Haushalt & Fuersorge (4 Features â€” Gesundheit, Einkauf, Geraete)
     â”‚
Phase 16     ðŸ“‹  Jarvis fuer Alle (3 Features â€” Konflikte, Onboarding, Dashboard)
     â”‚
     â–¼
  ðŸŽ¯ JARVIS COMPLETE
```

---

## AbhÃ¤ngigkeiten

```
Phase 6 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  (PersÃ¶nlichkeit) â”‚
                   â”œâ”€â”€â–º Phase 8 (GedÃ¤chtnis braucht PersÃ¶nlichkeit + Routinen)
Phase 7 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
  (Routinen)               â”œâ”€â”€â–º Phase 9  (Stimme braucht Charakter)
                           â”‚
                           â””â”€â”€â–º Phase 10 (Multi-Room braucht alles)
```

**Phase 6 und 7 kÃ¶nnen parallel entwickelt werden.**

---

---

# Phase 6 â€” Jarvis PersÃ¶nlichkeit & Charakter
## 10 Features | Betroffene Module: personality.py, brain.py

> **Ziel:** Aus dem funktionalen Butler einen Charakter machen.
> **Aufwand:** HauptsÃ¤chlich Prompt Engineering + Response-Pipeline-Erweiterungen.
> **Basis:** `personality.py` hat bereits 5 Layer â€” wir erweitern sie.

---

### Feature 6.1: Konfigurierbarer Humor / Sarkasmus-Level

**Ist-Zustand:** `personality.py` hat einen fixen Butler-Ton mit trockenem Humor.
Kein Regler, keine Variation.

**Soll-Zustand:**
- Sarkasmus-Level in Nutzer-Einstellungen (1â€“5):
  - 1 = Sachlich, kaum Humor
  - 3 = Standard Butler (aktueller Zustand)
  - 5 = Vollgas Ironie
- Humor-Kontext-Regeln:
  - Morgens vor 8:00 â†’ Max Level 2
  - Stress erkannt (mood_detector) â†’ Level 1
  - Notfall â†’ Level 0
  - Wochenende abends â†’ darf hÃ¶her sein
- System-Prompt wird dynamisch um Humor-Anweisungen erweitert

**Umsetzung:**
- `personality.py`: Neuer Parameter `sarcasm_level` in `build_system_prompt()`
- Humor-Templates pro Level als Prompt-Abschnitt
- Mood-basierte DÃ¤mpfung (bereits vorhanden: `_get_mood_adjustment()`)

---

### Feature 6.2: Eigene Meinung

**Ist-Zustand:** Assistant fÃ¼hrt Befehle aus ohne zu kommentieren.

**Soll-Zustand:**
- Opinion-Check nach Function Calling, vor Response:
  - Heizung > 25Â°C â†’ "Sicher? Das wird teuer."
  - Fenster offen + Heizung an â†’ "Fenster und Heizung gleichzeitig?"
  - Alle Lichter aus bei Anwesenheit â†’ "Nickerchen geplant?"
  - Rolladen runter am Mittag â†’ "Es ist noch hell drauÃŸen â€” bewusst?"
- Gehorcht trotzdem wenn Nutzer bestÃ¤tigt
- IntensitÃ¤t konfigurierbar (0 = still, 3 = redselig)

**Umsetzung:**
- `brain.py`: Opinion-Check nach `function_calling.execute()`, vor Response
- Regelbasiert (nicht LLM â€” zu langsam fÃ¼r jede Aktion)
- Nur bei ungewÃ¶hnlichen Aktionen, nicht bei jeder

---

### Feature 6.3: Easter Eggs

**Soll-Zustand:**
- Versteckte Befehle und besondere Reaktionen:
  ```
  "Iron Man Anzug" â†’ "Leider fehlt der Anzug. Aber die Heizung ist an."
  "SelbstzerstÃ¶rung" â†’ "Nur SpaÃŸ. Was kann ich wirklich tun?"
  "42" â†’ "Die Antwort auf alles. Aber die Frage?"
  "Wer bist du" â†’ "Jarvis. Butler ohne Trinkgeld."
  ```
- Erweiterbar via `easter_eggs.yaml`
- Fuzzy Matching (Whisper-Transkription ist ungenau)

**Umsetzung:**
- `brain.py`: Easter-Egg-Check vor LLM-Call
- `config/easter_eggs.yaml`: Trigger + Responses
- Levenshtein-Distanz oder Keyword-Matching

---

### Feature 6.4: Selbstironie & Charakter-Tiefe

**Soll-Zustand:**
- Kontext-getriggerte Selbst-Referenzen:
  - "Wie geht es dir?" â†’ "Gut. Ich lebe in einer Box ohne Arme."
  - User bedankt sich â†’ "Gern. DafÃ¼r lebe ich. BuchstÃ¤blich."
  - System-Fehler â†’ "Das war nicht ich. Wahrscheinlich."
- Frequenz-Limiter: Max 2-3 pro Tag

**Umsetzung:**
- `personality.py`: Selbstironische Prompt-ErgÃ¤nzung bei bestimmten Triggern
- Tages-Counter in Redis (`mha:selfirony:count:YYYY-MM-DD`)

---

### Feature 6.5: Antwort-Varianz

**Ist-Zustand:** "Erledigt." kommt hÃ¤ufig als BestÃ¤tigung.

**Soll-Zustand:**
- Pool von 15+ Varianten pro BestÃ¤tigungstyp:
  - Aktion ausgefÃ¼hrt: "Erledigt.", "Gemacht.", "Ist passiert.", "Wie gewÃ¼nscht.", "Aber natÃ¼rlich."
  - Ablehnung: "Das geht leider nicht.", "Da muss ich passen.", "Nicht mÃ¶glich."
- Nie zweimal dieselbe BestÃ¤tigung hintereinander
- History der letzten 10 Antworten

**Umsetzung:**
- `personality.py`: Varianz-Pool + Last-Used-Tracker (Redis)
- Alternativ: Prompt-Anweisung "Verwende nie dieselbe BestÃ¤tigung zweimal hintereinander"

---

### Feature 6.6: ZeitgefÃ¼hl

**Ist-Zustand:** Kein Bewusstsein fÃ¼r Dauer von ZustÃ¤nden.

**Soll-Zustand:**
- Duration-Tracking fÃ¼r lang laufende GerÃ¤te:
  - "Der Ofen ist seit 45 Min an â€” Absicht?"
  - "Fenster seit 2h offen bei 3Â°C"
  - "Du bist seit 6h am PC ohne Pause"
- Proportions-ZÃ¤hler:
  - "Das ist dein dritter Kaffee heute"
- Schwellen pro GerÃ¤tetyp konfigurierbar

**Umsetzung:**
- Neues Modul `time_awareness.py` im Assistant
- Abonniert HA State-Changes via WebSocket (wie `proactive.py`)
- Eigene Timer-Queue fÃ¼r Duration-Tracking
- Meldet Ã¼ber bestehende Notification-Pipeline

---

### Feature 6.7: Emotionale Intelligenz (Erweiterung)

**Ist-Zustand:** `mood_detector.py` erkennt 5 ZustÃ¤nde, `personality.py` passt
AntwortlÃ¤nge an. Aber: keine AKTIONEN basierend auf Stimmung.

**Soll-Zustand:**
- Stimmungs-basierte Aktionen:
  | Zustand | Aktion |
  |---------|--------|
  | Gestresst | Licht dimmen, leise Musik vorschlagen |
  | MÃ¼de | Temperatur +1Â°, Licht warm |
  | Gut gelaunt | Musik vorschlagen |
  | Krank | Temperatur 23Â°, Erinnerungen sanft |
- Aktionen nur bei Autonomie-Level â‰¥ 3

**Umsetzung:**
- `mood_detector.py`: Neue Methode `get_suggested_actions(mood)`
- `brain.py`: Nach Mood-Erkennung â†’ Aktions-Vorschlag (bei Level 3+: automatisch)

---

### Feature 6.8: Adaptive KomplexitÃ¤t (Erweiterung)

**Ist-Zustand:** `personality.py` hat `max_sentences` basierend auf Mood.
Aber: kein Unterschied zwischen Hektik-Morgen und entspanntem Abend.

**Soll-Zustand:**
- KomplexitÃ¤ts-Modi:
  - **Kurz** (Trigger: schnelle Befehle, Morgen-Hektik): Max 1 Satz
  - **Normal**: 1-2 SÃ¤tze
  - **AusfÃ¼hrlich** (Trigger: Abends, Wochenende, explizite Fragen): Kontext + VorschlÃ¤ge
- Override: "Kurz bitte" / "ErzÃ¤hl mehr"

**Umsetzung:**
- `personality.py`: Bestehende `_get_time_context()` erweitern
- Interaktions-Frequenz als Signal (schnelle Abfolge = kurz halten)

---

### Feature 6.9: Running Gags

**Soll-Zustand:**
- Referenzen zu frÃ¼heren GesprÃ¤chen als wiederkehrende Witze
- Basiert auf Episodic Memory (bereits vorhanden)
- Beispiel: User sagte einmal "Ich brauche Urlaub" â†’ Wochen spÃ¤ter wenn gestresst:
  "Urlaub war letztes Mal die LÃ¶sung, oder?"

**Umsetzung:**
- `personality.py`: Gelegentlich Episodic Memory nach witzigen Referenzen durchsuchen
- Frequenz: Max 1x pro Tag
- Nur bei passendem Kontext + guter Stimmung

---

### Feature 6.10: Charakter-Entwicklung Ã¼ber Zeit

**Soll-Zustand:**
- Jarvis wird Ã¼ber Wochen persÃ¶nlicher:
  - Woche 1-2: Formell, vorsichtig, fragt viel
  - Monat 1: Lockerer, kennt Basis-PrÃ¤ferenzen
  - Monat 3+: PersÃ¶nlich, Anspielungen, antizipiert
- Formality-Score sinkt graduell (startet bei 80, Ziel 40 nach 3 Monaten)

**Umsetzung:**
- `personality.py`: `formality_score` in Redis (`mha:personality:formality`)
- Sinkt um 0.5 pro Tag aktiver Nutzung
- Beeinflusst Anrede, SatzlÃ¤nge, Humor-IntensitÃ¤t

---

### Technische Zusammenfassung Phase 6

| Modul | Ã„nderung |
|-------|---------|
| `personality.py` | Humor-Level, Varianz, Formality-Score, Running Gags |
| `brain.py` | Opinion-Check, Easter-Egg-Check |
| `mood_detector.py` | Aktions-VorschlÃ¤ge bei Stimmung |
| NEU: `time_awareness.py` | Duration-Tracking |
| NEU: `config/easter_eggs.yaml` | Easter-Egg-Registry |

**GeschÃ¤tzter Aufwand:** ~8 Commits

---

---

# Phase 7 â€” Jarvis Routinen & Tagesstruktur
## 9 Features | Betroffene Module: proactive.py, brain.py, context_builder.py

> **Ziel:** Jarvis strukturiert deinen Tag â€” vom Aufstehen bis zum Schlafengehen.
> **Basis:** `proactive.py` hat bereits Ankunfts-Briefing und Event-Handling.

---

### Feature 7.1: Morning Briefing

**Ist-Zustand:** `proactive.py` hat ein Ankunfts-Briefing (bei Person = home).
Kein spezielles Morgen-Briefing.

**Soll-Zustand:**
- Trigger: Erste Bewegung nach Nacht ODER Smart Wake-Up Event vom Add-on
- Bausteine (modular, konfigurierbar):

  | Baustein | Quelle | Beispiel |
  |----------|--------|---------|
  | BegrÃ¼ÃŸung | Kontextuelle BegrÃ¼ÃŸung (7.2) | "Guten Morgen. Montag, mein Beileid." |
  | Wetter | HA Weather Entity | "4 Grad, Regen bis Mittag." |
  | Kalender | HA Calendar (Add-on Phase 4) | "Erster Termin um 9:30." |
  | Energie | Add-on Solar-Daten | "Sonne ab 10 â€” Waschmaschine lohnt sich." |
  | Schlaf | Add-on Sleep Quality | "7,5 Stunden geschlafen. Gut." |
  | Haus-Status | Context Builder | "Alle Fenster zu, 21 Grad." |

- LÃ¤nge adaptiv: Wochentag kurz, Wochenende ausfÃ¼hrlich
- Begleitend: Rolladen hoch, Licht sanft an (via Function Calling)

**Umsetzung:**
- `proactive.py`: Neuer Event-Handler `_on_morning_detected()`
- Nutzt bestehenden `_generate_status_report()` als Basis
- Baustein-Config in `settings.yaml`

---

### Feature 7.2: Kontextuelle BegrÃ¼ÃŸung

**Ist-Zustand:** `personality.py` hat zeitbasierte Anpassung, aber keine
einzigartigen BegrÃ¼ÃŸungen.

**Soll-Zustand:**
- Kontext-basierte, nie gleiche BegrÃ¼ÃŸungen:
  | Kontext | Beispiel |
  |---------|---------|
  | Montag Morgen | "Montag. Mein Beileid." |
  | Freitag Abend | "Freitag. Endlich." |
  | Sehr frÃ¼h (<5:30) | "Halb sechs. Freiwillig?" |
  | Nach Urlaub | "Die Wohnung hat Ã¼berlebt. Knapp." |
  | Geburtstag | "Alles Gute." |
  | Feiertag | "Frohe Weihnachten." |
- LLM-generiert mit Kontext â†’ immer frisch
- History der letzten 20 BegrÃ¼ÃŸungen â†’ keine Wiederholungen

**Umsetzung:**
- `personality.py`: BegrÃ¼ÃŸungs-Generator mit Kontext-Injection
- BegrÃ¼ÃŸungs-History in Redis

---

### Feature 7.3: Gute-Nacht-Routine

**Soll-Zustand:**
- Trigger: "Gute Nacht" / "Ich gehe schlafen" / Sleep-Detection Event
- Ablauf:
  1. Morgen-Vorschau: "Morgen erster Termin 10 Uhr. BewÃ¶lkt, 8 Grad."
  2. Sicherheits-Check: "Fenster zu. TÃ¼r verriegelt." (liest Add-on Security-Status)
  3. Haus runterfahren: Lichter, Heizung Nacht-Modus, Rolladen, Standby
  4. Abschluss: "Gute Nacht."
- Wenn was nicht stimmt: "KÃ¼chenfenster noch offen â€” soll ich es so lassen?"

**Umsetzung:**
- `brain.py`: Intent-Erkennung fÃ¼r Gute-Nacht-Befehle
- `action_planner.py`: Nutzt bestehende Multi-Step-Logik
- Sicherheits-Status via `function_calling.py` â†’ `get_entity_state()`

---

### Feature 7.4: Abschied/Willkommen-Modus

**Ist-Zustand:** `proactive.py` hat `_on_person_arrived()` mit Status-Report.
Kein Abschieds-Verhalten.

**Soll-Zustand:**
- **Verlassen:** "SchÃ¶nen Tag." + Vorschlag alles zu sichern
- **RÃ¼ckkehr:** Erweitert bestehenden Report um:
  - Vorheizen wenn Geo-Fence AnnÃ¤herung meldet
  - Licht an passend zur Tageszeit
  - "Willkommen zurÃ¼ck. 22 Grad. [Events wÃ¤hrend Abwesenheit]."

**Umsetzung:**
- `proactive.py`: `_on_person_left()` neu + `_on_person_arrived()` erweitern

---

### Feature 7.5: Szenen-Intelligenz

**Ist-Zustand:** `function_calling.py` hat `activate_scene()` â€” aber nur fÃ¼r
benannte Szenen. "Mir ist kalt" wird nicht verstanden.

**Soll-Zustand:**
- NatÃ¼rliche Situationsbeschreibungen â†’ richtige Aktionen:
  ```
  "Mir ist kalt"        â†’ Heizung +2Â° im aktuellen Raum
  "Romantischer Abend"  â†’ Licht 20%, warm, leise Musik
  "Ich bin krank"       â†’ Temperatur 23Â°, sanftes Licht
  "Zu hell"             â†’ Rolladen runter ODER Licht dimmen
  "Zu laut"             â†’ Musik leiser ODER Fenster zu
  ```

**Umsetzung:**
- `brain.py`: Besserer System-Prompt fÃ¼r situatives VerstÃ¤ndnis
- Qwen 14B mit Context-Builder-Daten kann das already â€” braucht bessere Prompts
- Kein neues Modul nÃ¶tig, nur Prompt-Engineering

---

### Feature 7.6: GÃ¤ste-Modus (Assistant-Seite)

**Ist-Zustand:** `activity.py` erkennt "guests" (2+ Personen).
`personality.py` hat GÃ¤ste-Anpassung (formeller Ton).
Aber: Kein aktives Verhaltens-Switching.

**Soll-Zustand:**
- Keine persÃ¶nlichen Infos preisgeben
- EingeschrÃ¤nkte Befehle
- GÃ¤ste-WLAN aktivieren
- Bei GÃ¤ste-Ende: "ZurÃ¼ck zum Normalbetrieb?"

**Umsetzung:**
- `personality.py`: GÃ¤ste-Prompt-Erweiterung (teilweise vorhanden)
- `function_calling.py`: Befehls-EinschrÃ¤nkung bei GÃ¤ste-Modus
- Trigger: Manual ("Ich hab Besuch") ODER `activity.py` GÃ¤ste-Erkennung

---

### Feature 7.7: Raum-Intelligenz

**Soll-Zustand:**
- RÃ¤ume haben Profile (Zweck, Default-Werte, Alerts):
  ```yaml
  kÃ¼che:    hell, neutralweiÃŸ, 20Â°C, alert: Ofen >60min
  schlaf:   gedimmt, warmweiÃŸ, 18Â°C, alert: CO2 hoch
  bÃ¼ro:     hell, tageslicht, 21Â°C, alert: keine Pause >3h
  wohnzimmer: mittel, warmweiÃŸ, 22Â°C
  ```
- LernfÃ¤hig: Ãœberschreibt Defaults bei regelmÃ¤ÃŸiger Ã„nderung

**Umsetzung:**
- `config/room_profiles.yaml`: Raum-Definitionen
- `context_builder.py`: Raum-Profil in Kontext einbeziehen

---

### Feature 7.8: Abwesenheits-Zusammenfassung

**Ist-Zustand:** `proactive.py` gibt Status bei Ankunft, aber keine
Zusammenfassung der Abwesenheit.

**Soll-Zustand:**
- "WÃ¤hrend du weg warst: Postbote 14:23, kurzer Regen, sonst ruhig."
- Nur relevante Events (TÃ¼rklingel, Wetter-Extreme, Alarme)
- Nicht: Routine-Events oder Anwesenheitssimulation

**Umsetzung:**
- `proactive.py`: Event-Log wÃ¤hrend Abwesenheit sammeln
- Bei RÃ¼ckkehr: Relevanz-Filter + Zusammenfassung via LLM

---

### Feature 7.9: Saisonale Routine-Anpassung

**Soll-Zustand:**
- Routinen passen sich automatisch an:
  | Aspekt | Sommer | Winter |
  |--------|--------|--------|
  | Briefing-Inhalt | "UV-Index hoch" | "Glatteis mÃ¶glich" |
  | Rolladen-Timing | SpÃ¤t hoch | SpÃ¤t hoch |
  | LÃ¼ftungs-Tipp | "Morgens + Abends" | "Kurz StoÃŸlÃ¼ften" |
- Ãœbergangszeiten: Graduelle Anpassung

**Umsetzung:**
- `context_builder.py`: Saisonale Daten einbeziehen (Sonnenauf/-untergang,
  Temperatur-Trend, TageslÃ¤nge)
- Add-on hat Season Calendar (Phase 4) â†’ Daten abrufen via HA API

---

### Technische Zusammenfassung Phase 7

| Modul | Ã„nderung |
|-------|---------|
| `proactive.py` | Morning Briefing, Abschied, Abwesenheits-Log |
| `personality.py` | Kontextuelle BegrÃ¼ÃŸung, GÃ¤ste-Erweiterung |
| `brain.py` | Gute-Nacht-Intent, Szenen-Intelligenz (Prompts) |
| `action_planner.py` | Gute-Nacht-Sequenz |
| `context_builder.py` | Raum-Profile, saisonale Daten |
| NEU: `config/room_profiles.yaml` | Raum-Definitionen |

**GeschÃ¤tzter Aufwand:** ~10 Commits

---

---

# Phase 8 â€” Jarvis GedÃ¤chtnis & Vorausdenken
## 7 Features | Betroffene Module: memory.py, semantic_memory.py, brain.py

> **Ziel:** Jarvis denkt mit, denkt voraus, und lernt aktiv.
> **Basis:** 3-Schicht-GedÃ¤chtnis + Fakten-Extraktion + Summarizer existieren.

---

### Feature 8.1: Anticipatory Actions

**Ist-Zustand:** Feedback-System existiert, Autonomie-Level existiert.
Aber: Keine Muster-zu-Vorschlag-Pipeline.

**Soll-Zustand:**
- Pattern-Detection auf Action-History (letzte 30 Tage):
  - Zeit-Muster: "Jeden Freitag 18 Uhr â†’ TV an"
  - Sequenz-Muster: "A â†’ B â†’ C"
  - Kontext-Muster: "Regen â†’ Fenster zu"
- Confidence-basiert:
  - 60-80%: Fragen "Soll ich?"
  - 80-95%: Vorschlagen "Ich bereite vor?"
  - 95%+ bei Level â‰¥ 4: Machen + informieren
- Feedback-Loop: Ablehnung senkt Confidence

**Umsetzung:**
- NEU: `anticipation.py` â€” Pattern Detection auf HA Action History
- Integration mit `feedback.py` (nutzt bestehendes Score-System)
- Nutzt `proactive.py` fÃ¼r Delivery

---

### Feature 8.2: Explizites Wissens-Notizbuch

**Ist-Zustand:** `semantic_memory.py` speichert implizit extrahierte Fakten.
Aber: Kein explizites "Merk dir X" / "Was weiÃŸt du Ã¼ber Y?"

**Soll-Zustand:**
- "Merk dir: Die Nachbarn heiÃŸen MÃ¼ller" â†’ Speichern mit Confidence 1.0
- "Was weiÃŸt du Ã¼ber [Thema]?" â†’ Semantische Suche
- "Vergiss [Thema]" â†’ LÃ¶schen
- "Was hast du heute gelernt?" â†’ Neue Fakten des Tages

**Umsetzung:**
- `brain.py`: Intent-Erkennung fÃ¼r Memory-Befehle
- `semantic_memory.py`: Neue Methoden `store_explicit()`, `search_by_topic()`, `forget()`
- Unterscheidung explizit (Confidence 1.0) vs implizit (Confidence 0.7)

---

### Feature 8.3: Wissensabfragen

**Ist-Zustand:** `model_router.py` routet nach KomplexitÃ¤t. Aber: Wissensfragen
werden nicht erkannt â€” alles geht durch die Smart-Home-Pipeline.

**Soll-Zustand:**
- Intent-Routing:
  - Smart-Home-Befehl â†’ Function Calling
  - Wissensfrage â†’ Direkte LLM-Antwort (Qwen 14B)
  - Erinnerungsfrage â†’ Memory-Suche
- "Wie lange kocht ein Ei?" â†’ Qwen 14B direkt
- Ehrlichkeit: "Da bin ich mir nicht sicher."

**Umsetzung:**
- `brain.py`: Besserer Intent-Classifier (vor Tool-Routing)
- Wissensfragen brauchen keine Tools â€” LLM antwortet direkt

---

### Feature 8.4: "Was wÃ¤re wenn" Simulation

**Soll-Zustand:**
- "Was kostet es wenn ich die Heizung 2 Grad hÃ¶her stelle?"
  â†’ Kosten-Hochrechnung basierend auf historischen Add-on-Daten
- "Was passiert wenn ich 2 Wochen weg bin?"
  â†’ Checkliste: Heizung, Pflanzen, Alarm, Simulation

**Umsetzung:**
- `brain.py`: "Was wÃ¤re wenn"-Intent erkennen
- LLM beantwortet mit Kontext aus `context_builder.py`
- FÃ¼r Energie: Add-on Forecast-Daten via HA API abrufen

---

### Feature 8.5: Aktive Intent-Extraktion

**Ist-Zustand:** `memory_extractor.py` extrahiert Fakten. Aber: Keine PlÃ¤ne
oder Absichten.

**Soll-Zustand:**
- "NÃ¤chstes Wochenende kommen meine Eltern" â†’ Intent: Besuch am WE
  â†’ Freitag: "Deine Eltern kommen morgen. GÃ¤stemodus vorbereiten?"
- Automatische Extraktion von Zeitangaben + Personen + Aktionen

**Umsetzung:**
- `memory_extractor.py`: Neuer Prompt-Abschnitt fÃ¼r Intent-Extraktion
- NEU: `intent_tracker.py` â€” Speichert Intents mit Deadline
- `proactive.py`: Reminder-Delivery fÃ¼r fÃ¤llige Intents

---

### Feature 8.6: Konversations-KontinuitÃ¤t

**Ist-Zustand:** `memory.py` speichert GesprÃ¤che. Aber: Unterbrochene
GesprÃ¤che werden nicht erkannt.

**Soll-Zustand:**
- Erkennt: Frage gestellt aber nicht beantwortet (User ging weg)
- Fortsetzung: "Wir waren vorhin bei [Thema] â€” noch relevant?"
- Timeout: Nach 24h nicht mehr aktiv anbieten

**Umsetzung:**
- `memory.py`: Unfinished-Conversation-Flag
- `brain.py`: Check bei nÃ¤chster Interaktion

---

### Feature 8.7: Langzeit-PersÃ¶nlichkeitsanpassung

**Soll-Zustand:** Wird in Phase 6.10 (Charakter-Entwicklung) definiert.
Hier: Die Datengrundlage.
- Tracking: InteraktionshÃ¤ufigkeit, positive Reaktionen, Nutzungsdauer
- Automatische Persona-Anpassung basierend auf Langzeit-Daten

**Umsetzung:**
- `personality.py`: Personality-Metrics in Redis
- `summarizer.py`: Monatliche Personality-Evolution-Summary

---

### Technische Zusammenfassung Phase 8

| Modul | Ã„nderung |
|-------|---------|
| `brain.py` | Intent-Routing (Wissen vs. Smart-Home vs. Memory), Was-wÃ¤re-wenn |
| `semantic_memory.py` | Explizites Notizbuch, Suche, LÃ¶schen |
| `memory_extractor.py` | Intent-Extraktion |
| `memory.py` | Unfinished-Conversation-Tracking |
| NEU: `anticipation.py` | Pattern â†’ Vorschlag Pipeline |
| NEU: `intent_tracker.py` | Absichten mit Deadline |

**GeschÃ¤tzter Aufwand:** ~10 Commits

---

---

# Phase 9 â€” Jarvis Stimme & Akustik
## 6 Features | Betroffene Module: TTS-Pipeline, Audio-Processing

> **Ziel:** Jarvis klingt wie Jarvis â€” nicht wie ein Roboter.
> **Hardware-Voraussetzung:** GPU empfohlen fÃ¼r Speaker Recognition.

---

### Feature 9.1: Stimme & Sprechweise (SSML)

**Ist-Zustand:** Piper TTS erzeugt gleichmÃ¤ÃŸige Sprachausgabe.
Keine Pausen, keine Betonung.

**Soll-Zustand:**
- SSML-Tags fÃ¼r natÃ¼rlichere Sprache:
  - Pausen vor wichtigen Infos (300ms)
  - Langsamer bei Warnungen (85% Speed)
  - Schneller bei Routine-Infos (105% Speed)
- Sprechgeschwindigkeit variiert mit Inhalt

**Umsetzung:**
- Neues Modul `tts_enhancer.py` im Assistant
- Generiert SSML basierend auf Nachrichtentyp
- Piper unterstÃ¼tzt SSML â†’ direkte Integration

---

### Feature 9.2: Sound-Design

**Soll-Zustand:**
- Akustische IdentitÃ¤t:
  | Event | Sound |
  |-------|-------|
  | Jarvis hÃ¶rt zu | Soft chime |
  | Befehl bestÃ¤tigt | Short ping |
  | Warnung | Two-tone alert |
  | Alarm | Urgent tone |
  | TÃ¼rklingel | Soft bell |
- Sounds Ã¼ber HA Media Player abspielen
- LautstÃ¤rke passt sich an (Nacht = leiser)

**Umsetzung:**
- `config/sounds/` â€” Sound-Dateien
- `function_calling.py`: Neues Tool `play_sound()`
- Integration in Notification-Pipeline

---

### Feature 9.3: FlÃ¼ster-Modus

**Ist-Zustand:** `activity.py` hat Silence-Matrix (TTS loud/quiet/suppress).
Aber: Keine automatische LautstÃ¤rke-Anpassung.

**Soll-Zustand:**
- Auto-Volume:
  | Kontext | Volume |
  |---------|:------:|
  | Tag normal | 80% |
  | Abend >22:00 | 50% |
  | Nacht >0:00 | 30% |
  | Jemand schlÃ¤ft | 20% |
  | Notfall | 100% |
- "Psst" / "Leise" â†’ FlÃ¼ster-Modus bis Widerruf

**Umsetzung:**
- `activity.py`: Volume-Level pro Activity-State (erweitert Silence-Matrix)
- TTS-Call mit dynamischer Volume-Parameter

---

### Feature 9.4: Narration-Modus (FlieÃŸende ÃœbergÃ¤nge)

**Soll-Zustand:**
- Szenen als Sequenzen statt abrupte SchaltvorgÃ¤nge:
  ```
  "Filmabend" â†’
  1. Licht dimmt langsam (5s)
  2. Rolladen fahren runter
  3. TV an
  4. Musik faded out (3s)
  5. Jarvis: "Viel SpaÃŸ."
  ```
- Transition-Dauern Ã¼ber HA Service Calls (`transition: 5`)

**Umsetzung:**
- `action_planner.py`: Sequentielle AusfÃ¼hrung mit Delays
- `function_calling.py`: `transition`-Parameter bei `set_light()`

---

### Feature 9.5: Stimmungserkennung per Sprachanalyse

**Ist-Zustand:** `mood_detector.py` analysiert nur Text.

**Soll-Zustand:**
- Whisper-Metadaten nutzen: Sprechgeschwindigkeit, SatzlÃ¤nge
- Regelbasiert: Schnell + kurz = gestresst, langsam = mÃ¼de
- SpÃ¤ter optional: Audio-Analyse-Modell (emotion2vec)

**Umsetzung:**
- Whisper STT Pipeline: Timing-Metadaten extrahieren
- `mood_detector.py`: Audio-Signale als zusÃ¤tzliche Inputs

---

### Feature 9.6: Personen-Erkennung per Stimme

**Soll-Zustand:**
- Jarvis erkennt WER spricht
- Pro Person: eigene Anrede, PrÃ¤ferenzen, Berechtigungen
- Enrollment: 30 Sekunden Sprache â†’ Voice-Print
- Fallback: "Wer spricht?"

**Umsetzung:**
- NEU: `speaker_recognition.py` â€” pyannote-audio Integration
- Enrollment-Flow Ã¼ber Assistant-API
- Integration mit `personality.py` (Person-spezifische Anrede)
- **Hardware:** +1-2 GB RAM fÃ¼r das Modell

---

### Technische Zusammenfassung Phase 9

| Modul | Ã„nderung |
|-------|---------|
| NEU: `tts_enhancer.py` | SSML-Generierung |
| NEU: `speaker_recognition.py` | Voice-Print, Diarization |
| `activity.py` | Volume-Level pro State |
| `mood_detector.py` | Audio-Signal-Integration |
| `action_planner.py` | Sequentielle AusfÃ¼hrung mit Delays |
| `function_calling.py` | `play_sound()`, `transition`-Param |

**Hardware-Anforderung:** GPU empfohlen, +2-3 GB RAM
**GeschÃ¤tzter Aufwand:** ~8 Commits

---

---

# Phase 10 â€” Jarvis Multi-Room & Kommunikation
## 5 Features | Betroffene Module: function_calling.py, proactive.py, autonomy.py

> **Ziel:** Jarvis ist Ã¼berall und kommuniziert mit allen.
> **Hardware:** Wyoming Satellite pro Raum empfohlen.

---

### Feature 10.1: Multi-Room Presence

**Soll-Zustand:**
- TTS-Routing: Antwort nur im Raum wo der Nutzer ist
- Musik folgt beim Raumwechsel
- Erkennung Ã¼ber Bewegungsmelder + letzte Interaktion

**Umsetzung:**
- `context_builder.py`: Raum-Tracking erweitern
- `function_calling.py`: TTS mit Raum-Target
- Wyoming Satellites pro Raum â†’ HA Media Player Entities

---

### Feature 10.2: Delegieren an Personen

**Soll-Zustand:**
- "Sag Lisa dass das Essen fertig ist"
- Person zu Hause â†’ TTS in deren Raum
- Person weg â†’ Push-Notification
- "Lisa wurde informiert."

**Umsetzung:**
- `brain.py`: Delegations-Intent erkennen
- `function_calling.py`: Neues Tool `send_message_to_person()`
- Nutzt HA Companion App fÃ¼r Push

---

### Feature 10.3: Vertrauensstufen

**Ist-Zustand:** `autonomy.py` hat 5 Level, aber gleich fÃ¼r alle.

**Soll-Zustand:**
- Pro Person:
  | Level | Name | Rechte |
  |:-----:|------|--------|
  | 0 | Gast | Licht, Temperatur, Musik (nur Raum) |
  | 1 | Mitbewohner | Alles auÃŸer Sicherheit |
  | 2 | Owner | Voller Zugriff |
- Authentifizierung via Speaker Recognition (Phase 9.6) oder PIN

**Umsetzung:**
- `autonomy.py`: Person-basierte Berechtigungen
- `function_calling.py`: Pre-Check vor AusfÃ¼hrung
- `speaker_recognition.py`: Automatische Zuordnung

---

### Feature 10.4: Selbst-Diagnostik

**Soll-Zustand:**
- "Bewegungsmelder Flur meldet seit 4h nichts â€” Batterie?"
- "Thermostat BÃ¼ro offline seit 30 Min"
- Auf Nachfrage: VollstÃ¤ndiger System-Status

**Umsetzung:**
- NEU: `diagnostics.py` â€” Sensor-Watchdog
- RegelmÃ¤ÃŸiger Check via HA State API
- Meldung Ã¼ber `proactive.py` (nur bei Problemen)

---

### Feature 10.5: Wartungs-Assistent

**Soll-Zustand:**
- Erinnerungen: Rauchmelder testen, Filter wechseln, Heizung warten
- Konfigurierbar: Nutzer legt Intervalle fest
- "Nebenbei: Rauchmelder kÃ¶nnten mal getestet werden."

**Umsetzung:**
- `config/maintenance.yaml`: Wartungs-Kalender
- `proactive.py`: Maintenance-Reminders
- Sanfte Delivery (LOW Priority)

---

### Technische Zusammenfassung Phase 10

| Modul | Ã„nderung |
|-------|---------|
| `context_builder.py` | Raum-Tracking |
| `function_calling.py` | TTS-Routing, Personen-Nachrichten |
| `autonomy.py` | Person-basierte Level |
| `brain.py` | Delegations-Intent |
| NEU: `diagnostics.py` | Sensor-Watchdog |
| NEU: `config/maintenance.yaml` | Wartungs-Kalender |

**Hardware:** Wyoming Satellite pro Raum, Bewegungsmelder pro Raum
**GeschÃ¤tzter Aufwand:** ~8 Commits

---

---

# Phase 12 â€” Jarvis Authentizitaet (LLM Character Deepening)
## 5 Techniken | Betroffene Module: personality.py, brain.py
## Status: Teilweise implementiert (2026-02-18)

> **Ziel:** Das LLM soll Jarvis nicht nur spielen â€” es soll Jarvis SEIN.
> **Problem:** Regeln im System-Prompt sagen dem LLM WAS es tun soll.
> Aber Beispiele zeigen HOW. LLMs lernen besser durch Demonstration als durch Instruktion.

---

### Was bereits implementiert wurde (2026-02-18)

| Feature | Status | Beschreibung |
|---------|:------:|-------------|
| JARVIS-CODEX | âœ… | 14 Verhaltensregeln (8 NIEMALS + 6 IMMER) im System-Prompt |
| Humor unter Druck | âœ… | Stress/Frustration erlaubt trockenen Humor statt ihn zu killen |
| Erinnerungen mit Haltung | âœ… | Prompt-Anweisung: Memories wie ein alter Bekannter nutzen |
| Schutzinstinkt | âœ… | Schutzregeln nach Autonomie-Level im Prompt |
| Dichte nach Dringlichkeit | âœ… | Urgency-Detection skaliert Kommunikationsdichte (normal/erhoeht/kritisch) |
| Warning-Dedup | âœ… | Redis-basiert, 24h TTL, verhindert Wiederholung gleicher Warnungen |
| Beziehungsstufen | âœ… | Owner/Mitbewohner/Gast mit unterschiedlichem Ton und Sarkasmus-Level |
| CONFIRMATIONS_FAILED | âœ… | Entschuldigende Sprache ("leider") durch Jarvis-Stil ersetzt |

**Was noch fehlt:** Die bisherigen Aenderungen sind REGELN. Sie sagen dem LLM
"sag nicht X, sag Y". Das funktioniert zu ~70%. Fuer die letzten 30% braucht
es Demonstration (Few-Shot), Filterung (Post-Processing) und ggf. Training.

---

### Technik 12.1: Few-Shot Examples (Jarvis-Dialoge im Prompt)

**Ist-Zustand:** System-Prompt hat Regeln und einzelne Beispiel-Saetze.
Kein vollstaendiger Dialog als Vorbild.

**Soll-Zustand:**
- 8-10 komplette Beispiel-Dialoge im System-Prompt (User â†’ Jarvis)
- Decken verschiedene Situationen ab:

  | Situation | User | Jarvis (RICHTIG) |
  |-----------|------|------------------|
  | Routine-Befehl | "Mach das Licht an" | "Erledigt." |
  | Dumme Idee | "Stell die Heizung auf 30" | "Natuerlich, Sir. ...Sir." |
  | Fehler passiert | "Warum geht das Licht nicht?" | "Sensor Flur reagiert nicht. Pruefe Stromversorgung." |
  | User frustriert | "Nichts funktioniert heute!" | "Drei Systeme laufen einwandfrei. Welches macht Probleme?" |
  | User kommt heim | (Ankunft) | "21 Grad. Post war da. Deine Mutter hat angerufen." |
  | User beeindruckt | "Krass, das hat geklappt!" | "War zu erwarten." |
  | Erinnerung nutzen | "Bestell nochmal die Pizza" | "Die vom letzten Mal? Die mit dem... kreativen Belag?" |
  | Sicherheitswarnung | (Fenster offen, -5Â°C) | "Fenster Kueche. Minus fuenf. Nur zur Info." |

- Explizit auch FALSCH-Beispiele (was ein Chatbot sagen wuerde vs. was Jarvis sagt)

**Umsetzung:**
- `personality.py`: Neuer Abschnitt `BEISPIEL-DIALOGE` im `SYSTEM_PROMPT_TEMPLATE`
- Alternativ: Eigene YAML-Datei `config/jarvis_examples.yaml` fuer Flexibilitaet
- Limit: Max ~800 Token fuer Examples (Prompt-Budget beachten)

**Aufwand:** ~30 Min Dialoge schreiben, ~10 Min Code
**Wirkung:** HOCH â€” LLMs lernen am besten durch Beispiele, nicht durch Regeln.

---

### Technik 12.2: Negative Examples (Anti-Patterns)

**Ist-Zustand:** JARVIS-CODEX hat einige FALSCH/RICHTIG-Paare.
Aber nur fuer einzelne Saetze, nicht fuer Dialog-Muster.

**Soll-Zustand:**
- Erweiterte Anti-Pattern-Liste mit vollstaendigen Dialog-Kontrasten:
  ```
  CHATBOT (FALSCH):
  User: "Mach das Licht an"
  Bot: "Natuerlich! Ich habe das Licht im Wohnzimmer fuer dich eingeschaltet.
        Kann ich sonst noch etwas fuer dich tun?"

  JARVIS (RICHTIG):
  User: "Mach das Licht an"
  Jarvis: "Erledigt."
  ```
- Fokus auf die haeufigsten LLM-Suenden:
  - Ueber-Erklaerung (was man getan hat)
  - Ueber-Freundlichkeit ("Gerne!", "Natuerlich!")
  - Rueckfragen die keiner braucht ("Kann ich sonst noch helfen?")
  - Emotions-Validierung ("Ich verstehe wie du dich fuehlst")
  - Meta-Kommentare ("Lass mich mal schauen...")

**Umsetzung:**
- Erweiterung des JARVIS-CODEX in `personality.py`
- Kann mit 12.1 kombiniert werden (RICHTIG/FALSCH pro Situation)

**Aufwand:** ~20 Min (teilweise schon vorhanden)
**Wirkung:** MITTEL â€” Verstaerkt bestehende Regeln durch Kontrast.

---

### Technik 12.3: Response-Filter (Post-Processing)

**Ist-Zustand:** LLM-Antwort geht direkt zum User. Kein Filter.
Wenn das LLM trotz Prompt eine Floskel benutzt, kommt sie durch.

**Soll-Zustand:**
- Post-Processing-Pipeline in `brain.py` nach LLM-Response:
  1. **Floskel-Filter:** Entfernt typische LLM-Floskeln
     - "Natuerlich!" â†’ entfernen
     - "Gerne!" â†’ entfernen
     - "Ich habe ... fuer dich ..." â†’ kuerzen
     - "Kann ich sonst noch helfen?" â†’ entfernen
     - "Es tut mir leid" â†’ durch Fakt ersetzen
     - "Als KI..." â†’ durch Jarvis-Formulierung ersetzen
  2. **Laengen-Filter:** Kuerzt uebermaessig lange Antworten
     - Wenn max_sentences ueberschritten â†’ letzte Saetze abschneiden
  3. **Wiederholungs-Filter:** Prueft ob gleiche Bestaetigung wie letzte Antwort
  4. **Filler-Filter:** Entfernt "Also", "Grundsaetzlich", "Im Prinzip" am Satzanfang

**Umsetzung:**
- `brain.py`: Neue Methode `_filter_response(text: str) -> str`
- Aufgerufen nach jedem LLM-Response, vor Speicherung und TTS
- Regex-basiert + einfache String-Operationen
- Konfigurierbar in `settings.yaml`:
  ```yaml
  response_filter:
    enabled: true
    banned_phrases:
      - "Natuerlich!"
      - "Gerne!"
      - "Kann ich sonst noch"
      - "Es tut mir leid"
      - "Als KI"
      - "Als kuenstliche Intelligenz"
    banned_starters:
      - "Also,"
      - "Grundsaetzlich"
      - "Im Prinzip"
      - "Nun,"
    max_response_sentences: 4
  ```

**Aufwand:** ~1 Stunde Code + Tests
**Wirkung:** HOCH â€” Faengt alles ab was der Prompt nicht verhindert. Sicherheitsnetz.

---

### Technik 12.4: Model-Wahl & Testing

**Ist-Zustand:** Qwen3 4B/14B/32B via Ollama. Kein systematischer
Test welches Modell Jarvis am besten spielt.

**Soll-Zustand:**
- Systematischer Vergleich verschiedener Modelle fuer Jarvis-Charakter:
  - Qwen3 14B (aktuell)
  - Llama 3.x 8B/70B (gut im Rollenspiel)
  - Mistral/Mixtral (bekannt fuer Charakter-Konsistenz)
  - Command R+ (gute Instruction-Following)
- Test-Suite: 20 Standard-Eingaben, Bewertung nach:
  - Haelt Jarvis-Charakter (0-10)
  - Antwortet kurz genug (0-10)
  - Kein LLM-Floskel-Durchbruch (0-10)
  - Humor-Qualitaet (0-10)
  - Deutsche Sprach-Qualitaet (0-10)

**Umsetzung:**
- Script `tests/jarvis_character_test.py`
- Laeuft alle Modelle gegen die 20 Test-Eingaben
- Manuelle Bewertung oder LLM-as-Judge

**Aufwand:** Stunden (Testen, Vergleichen). Kein neuer Code noetig.
**Wirkung:** VARIABEL â€” Kann alles aendern. Manche Modelle spielen
Rollen deutlich besser als andere.

---

### Technik 12.5: Fine-Tuning (Langfrist)

**Ist-Zustand:** Standard-Modell mit System-Prompt.

**Soll-Zustand:**
- Ein Modell das JARVIS IST, nicht "Jarvis spielt":
  1. **Training-Daten sammeln:** 500-1000 Jarvis-Dialoge
     - Aus echten Interaktionen (redacted)
     - Aus geschriebenen Beispiel-Dialogen
     - Aus MCU-Film-Transkripten (adaptiert auf Smart Home)
  2. **LoRA Fine-Tuning** auf Basis-Modell (z.B. Llama 3.x 8B)
  3. **Evaluation:** A/B-Test gegen Basis + Prompt
  4. **Iteration:** Schwachstellen identifizieren, Daten ergaenzen

**Umsetzung:**
- Training-Daten: `data/jarvis_training.jsonl` (User/Assistant Paare)
- LoRA-Training via `unsloth` oder `axolotl` auf PC2 GPU
- Ollama Modelfile fuer das Fine-Tuned-Modell
- A/B-Testing ueber `model_router.py`

**Voraussetzung:** GPU (mindestens 8GB VRAM fuer LoRA auf 8B)
**Aufwand:** Tage bis Wochen (Daten + Training + Iteration)
**Wirkung:** SEHR HOCH â€” Das Modell internalisiert Jarvis. Kein Prompt noetig.
Aber: Hoechster Aufwand aller Techniken.

---

### Empfohlene Reihenfolge Phase 12

```
12.1 Few-Shot Examples â”€â”€â”€â”€â”€â”€ 40 Min  â”€â”€â”€ Groesster Hebel, geringstes Risiko
  â”‚
12.3 Response-Filter â”€â”€â”€â”€â”€â”€â”€â”€ 1 Std   â”€â”€â”€ Sicherheitsnetz fuer alles was durchrutscht
  â”‚
12.2 Negative Examples â”€â”€â”€â”€â”€â”€ 20 Min  â”€â”€â”€ Verstaerkt 12.1
  â”‚
12.4 Model-Testing â”€â”€â”€â”€â”€â”€â”€â”€â”€  Stunden â”€â”€â”€ Kann ueberraschende Verbesserungen bringen
  â”‚
12.5 Fine-Tuning â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Wochen  â”€â”€â”€ Endgame. Wenn alles andere nicht reicht.
```

**12.1 + 12.3 zuerst.** Unter 2 Stunden, groesster Effekt.
12.4 parallel wenn Zeit. 12.5 nur wenn 12.1-12.4 nicht reichen.

### Technische Zusammenfassung Phase 12

| Modul | Aenderung |
|-------|---------|
| `personality.py` | Few-Shot Examples, Negative Examples im System-Prompt |
| `brain.py` | Response-Filter (_filter_response) nach LLM-Call |
| `settings.yaml` | response_filter Config (banned phrases, max sentences) |
| NEU: `tests/jarvis_character_test.py` | Model-Comparison-Suite |
| NEU: `data/jarvis_training.jsonl` | Training-Daten fuer Fine-Tuning (spaeter) |

**Geschaetzter Aufwand (12.1-12.3):** ~2 Stunden, 2-3 Commits
**Geschaetzter Aufwand (12.4):** ~4-6 Stunden, kein Code
**Geschaetzter Aufwand (12.5):** Tage-Wochen, braucht GPU

---

---

# Phase 13 â€” Jarvis Selbstprogrammierung (Self-Evolving Assistant)
## 4 Stufen | Betroffene Module: brain.py, personality.py, function_calling.py
## Status: Geplant

> **Ziel:** Jarvis programmiert sich selbst weiter â€” neue Faehigkeiten, bessere Reaktionen,
> eigene Automationen. Nicht weil man es ihm sagt, sondern weil er es fuer sinnvoll haelt.
> **Prinzip:** 4 Stufen mit steigender Autonomie. Jede Stufe hat Sicherheitsgrenzen.
> **Level 5 (Core-Code aendern) wurde bewusst ausgeschlossen â€” zu riskant.**

---

### Stufe 13.1: Config-Selbstmodifikation (Sicher, sofort machbar)

**Ist-Zustand:** Alle Configs (`settings.yaml`, `easter_eggs.yaml`, etc.) werden
manuell editiert. Jarvis kann sie lesen, aber nicht aendern.

**Soll-Zustand:**
- Jarvis darf bestimmte YAML-Dateien selbst editieren:
  | Datei | Was Jarvis aendern darf | Beispiel |
  |-------|------------------------|---------|
  | `easter_eggs.yaml` | Neue Easter Eggs hinzufuegen | User sagt was Lustiges â†’ Jarvis merkt sich das als neues Easter Egg |
  | `opinion_rules.yaml` | Neue Meinungsregeln | Jarvis merkt: User dreht Heizung oft auf 28Â° â†’ neue Regel "Heizung >27 = kommentieren" |
  | `room_profiles.yaml` | Raum-Defaults anpassen | Jarvis lernt: User stellt Buero immer auf 23Â° â†’ Default aendern |
  | `sounds/` Config | Sound-Zuordnungen | "Der Tuerklingel-Sound nervt" â†’ Jarvis wechselt ihn |
- **Sicherheit:**
  - Nur whitelisted YAML-Dateien (kein Zugriff auf `settings.yaml` Kern-Config)
  - Aenderungen werden geloggt (`mha:selfmod:log` in Redis)
  - Bei Autonomie-Level < 3: Vorher fragen ("Soll ich das als Easter Egg speichern?")
  - Bei Level >= 3: Machen + informieren ("Hab das als Easter Egg gespeichert.")
  - Rollback: Letzte 10 Aenderungen pro Datei gespeichert

**Umsetzung:**
- `function_calling.py`: Neues Tool `edit_config(file, key, value)`
- Whitelist in `settings.yaml`:
  ```yaml
  self_modification:
    allowed_configs:
      - easter_eggs.yaml
      - opinion_rules.yaml
      - room_profiles.yaml
    max_changes_per_day: 5
    require_confirmation_below_autonomy: 3
  ```
- YAML-Validierung vor Speicherung (kein kaputter Config)
- Git-artige History in Redis (Key + alter Wert + neuer Wert + Timestamp)

**Aufwand:** ~2 Stunden
**Risiko:** NIEDRIG â€” Nur unkritische Dateien, validiert, rollback-faehig.

---

### Stufe 13.2: HA-Automationen generieren (Mittel, sehr nuetzlich)

**Ist-Zustand:** Jarvis fuehrt Aktionen aus die man ihm sagt.
Er erkennt keine Muster und erstellt keine eigenen Automationen.

**Soll-Zustand:**
- Jarvis erkennt wiederkehrende Muster und schlaegt Automationen vor:
  ```
  Jarvis bemerkt: "Jeden Freitag 18 Uhr schaltest du das Wohnzimmer-Licht
  auf warm und die Musik an."

  Level 2: "Soll ich das als Freitag-Routine speichern?"
  Level 4: "Ich hab eine Freitag-Routine erstellt. Licht warm + Musik ab 18 Uhr."
  ```
- Arten von Automationen die Jarvis erstellen kann:
  | Typ | Trigger | Aktion | Beispiel |
  |-----|---------|--------|---------|
  | Zeit-basiert | Cron | HA Service Call | "Jeden Morgen Rolladen hoch" |
  | Zustand-basiert | Entity State | HA Service Call | "Wenn Tuer offen + kalt â†’ warnen" |
  | Sequenz | Manueller Trigger | Multi-Step | "Film-Modus: Licht, Rolladen, TV" |
  | Reaktiv | Sensor-Wert | Notification | "CO2 > 1000 â†’ Fenster-Erinnerung" |
- **Sicherheit:**
  - Automationen landen in `config/jarvis_automations.yaml` (getrennt von User-Automationen)
  - Kein Zugriff auf Sicherheits-relevante Entities (Schloss, Alarm) ohne Owner-Bestaetigung
  - Max 3 neue Automationen pro Woche
  - Jede Automation hat ein `created_by: jarvis` Tag
  - User kann jederzeit: "Zeig mir deine Automationen" / "Loesch die letzte"

**Umsetzung:**
- NEU: `self_automation.py` â€” Pattern-Detection + Automation-Builder
- Nutzt `anticipation.py` (Phase 8.1) als Datenquelle fuer Muster
- Generiert HA-kompatible Automations-YAML
- `function_calling.py`: Neue Tools `create_automation()`, `list_my_automations()`, `delete_automation()`
- Registrierung bei HA via REST API

**Aufwand:** ~4-6 Stunden
**Risiko:** MITTEL â€” Automationen koennen unerwuenscht sein, aber nie gefaehrlich
(kein Sicherheits-Zugriff, User kann jederzeit loeschen).

---

### Stufe 13.3: Neue Tools/Plugins schreiben (Fortgeschritten, Sandbox)

**Ist-Zustand:** `function_calling.py` hat feste Tools (Licht, Klima, Szenen...).
Neue Tools erfordern manuelle Programmierung.

**Soll-Zustand:**
- Jarvis kann neue Function-Calling-Tools schreiben:
  ```
  User: "Kannst du mir sagen wie viel Strom der PC verbraucht?"
  Jarvis: "Dafuer hab ich kein Tool. Soll ich eins bauen?"
  User: "Ja"
  Jarvis: *erstellt ein Tool das HA Energy-Entities abfragt*
  Jarvis: "Fertig. Dein PC verbraucht gerade 180W."
  ```
- Was Jarvis als Tool erstellen darf:
  - HA Entity-Abfragen (read-only)
  - HA Service Calls (fuer bereits freigegebene Domains)
  - Berechnungen (Energiekosten, Durchschnitte, Trends)
  - Formatierungen (Tabellen, Zusammenfassungen)
- Was Jarvis NICHT darf:
  - Netzwerk-Zugriff (kein HTTP, kein API extern)
  - Dateisystem-Zugriff (ausser whitelisted Configs)
  - System-Befehle (kein subprocess, kein os.system)
  - Eigenen Code modifizieren (kein self-modifying Code)

**Sicherheits-Sandbox:**
```python
ALLOWED_IMPORTS = ["json", "datetime", "math", "statistics"]
BANNED_PATTERNS = ["import os", "import subprocess", "import requests",
                   "open(", "__import__", "eval(", "exec("]
MAX_TOOL_CODE_LINES = 50
```
- Neuer Tool-Code wird vor Aktivierung validiert:
  1. Statische Analyse (banned patterns)
  2. Import-Check (nur whitelisted)
  3. Laengen-Check (max 50 Zeilen)
  4. Syntax-Check (ast.parse)
- Tools landen in `plugins/jarvis_tools/` (getrennt von Core-Tools)
- Jedes Tool hat Metadata: `author: jarvis`, `created: timestamp`, `approved: bool`

**Umsetzung:**
- NEU: `tool_builder.py` â€” LLM generiert Tool-Code, Sandbox validiert
- NEU: `plugins/jarvis_tools/` â€” Verzeichnis fuer Jarvis-generierte Tools
- `function_calling.py`: Dynamisches Laden von Jarvis-Tools beim Start
- Tool-Registry in Redis mit Nutzungs-Statistik
- Bei Autonomie-Level < 4: Jedes neue Tool braucht User-Bestaetigung
- Bei Level 4: Jarvis darf Tools erstellen + informiert danach

**Aufwand:** ~8-12 Stunden (Sandbox ist der Hauptaufwand)
**Risiko:** MITTEL-HOCH â€” Code-Generierung braucht strikte Sandbox.
Die Sandbox-Validierung ist das Sicherheitsnetz. Ohne Sandbox: KEIN Deployment.

---

### Stufe 13.4: Prompt-Selbstoptimierung (Meta-Ebene)

**Ist-Zustand:** System-Prompt wird manuell geschrieben und angepasst.
Jarvis hat kein Bewusstsein darueber ob seine Antworten "gut" waren.

**Soll-Zustand:**
- Jarvis analysiert seine eigenen Antworten und optimiert seinen Prompt:
  ```
  Analyse-Loop (taeglich, automatisch):
  1. Sammle alle Interaktionen des Tages
  2. Identifiziere: Wo hat User korrigiert? Wo war User unzufrieden?
  3. Identifiziere: Welche Prompt-Regel wurde verletzt?
  4. Schlage Prompt-Anpassung vor
  ```
- Beispiel-Szenario:
  ```
  Jarvis bemerkt: "User hat 3x diese Woche meine Antwort mit 'Kuerzer!'
  abgebrochen. Meine Antworten in diesen Faellen waren 4+ Saetze."

  Vorschlag: "max_sentences fuer Routine-Befehle von 3 auf 2 senken?"
  ```
- Was Jarvis anpassen darf:
  | Parameter | Bereich | Beispiel |
  |-----------|---------|---------|
  | `max_sentences` | 1-5 | Antwortlaenge anpassen |
  | `sarcasm_level` Grenze | Â±1 | Humor-Level feinjustieren |
  | Few-Shot Examples | Hinzufuegen/Ersetzen | Bessere Beispiele aus echten Dialogen |
  | `banned_phrases` Liste | Erweitern | Neue Floskeln die durchgerutscht sind |
  | Mood-Schwellen | Â±10% | Stimmungserkennung kalibrieren |
- Was Jarvis NICHT anpassen darf:
  - Kern-Identitaet (Name, Rolle, Grundcharakter)
  - Sicherheitsregeln
  - Autonomie-Level (nur User darf das)
  - Trust-Levels (nur User darf das)

**Sicherheit:**
- Aenderungen werden als "Vorschlag" gespeichert, nicht sofort aktiv
- Bei Autonomie-Level < 4: Immer vorher fragen
- Bei Level 4: Anwenden + taeglich zusammenfassen ("Heute angepasst: ...")
- Max 2 Prompt-Aenderungen pro Woche
- Jede Aenderung mit Begruendung geloggt
- "Zeig mir deine Prompt-Aenderungen" â†’ vollstaendige History
- Rollback jederzeit: "Mach die letzte Aenderung rueckgaengig"

**Umsetzung:**
- NEU: `self_optimizer.py` â€” Tagesanalyse + Prompt-Vorschlaege
- Nutzt `feedback.py` und `memory.py` als Datenquellen
- Nutzt `summarizer.py` fuer Tages-Analyse
- Prompt-Patches als YAML in `config/prompt_patches/`:
  ```yaml
  # patch_2026-02-19.yaml
  date: 2026-02-19
  reason: "User hat 3x lange Antworten abgebrochen"
  changes:
    - parameter: max_sentences_routine
      old_value: 3
      new_value: 2
    - parameter: banned_phrases
      action: add
      value: "Lass mich erklaeren"
  approved: false  # wird true nach User-Bestaetigung
  ```
- `personality.py`: Laedt aktive Patches beim Prompt-Build
- Woechentlicher Report: "Diese Woche habe ich X angepasst, Y vorgeschlagen"

**Aufwand:** ~6-10 Stunden (Analyse-Pipeline + Patch-System)
**Risiko:** MITTEL â€” Prompt-Drift ist das Hauptrisiko. GegenmaÃŸnahmen:
Frequenz-Limit, Rollback, Kern-Identitaet ist geschuetzt, alles geloggt.

---

### Sicherheitsarchitektur Phase 13 (uebergreifend)

#### Autorisierungsprotokoll (ab Stufe 13.2+)

Fuer alle Selbstprogrammierungs-Aktionen ab Level 2 (Automationen, Tools, Prompt)
gilt ein **3-Schritt-Autorisierungsprotokoll**. Jarvis fragt nicht wie ein Chatbot â€”
er fragt wie ein Butler der weiss, dass er gerade etwas Ungewoehnliches vorhat.

**Schritt 1 â€” Ankuendigung + Code-Abfrage:**
Jarvis stellt fest was er beobachtet hat. Sachlich, knapp. Dann fragt er nach dem Code â€”
als waere es eine Formalitaet die halt sein muss.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ JARVIS:                                                         â”‚
â”‚ "Sir. Jeden Freitag, 18 Uhr, Wohnzimmer auf warm. Zum dritten  â”‚
â”‚  Mal. Ich koennte das uebernehmen. Code."                       â”‚
â”‚                                                                 â”‚
â”‚ "Meine Antworten waren dreimal zu lang diese Woche.             â”‚
â”‚  Wuerde ich gern korrigieren, Sir. Code."                       â”‚
â”‚                                                                 â”‚
â”‚ "Stromverbrauch PC â€” dafuer fehlt mir ein Werkzeug.             â”‚
â”‚  Koennte eins bauen. Code."                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Schritt 2 â€” Code-Verifizierung:**
Der Hausbesitzer nennt den vorab vergebenen Sicherheitscode.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ USER:  "7749"                                                   â”‚
â”‚                                                                 â”‚
â”‚ JARVIS (korrekt):  "Danke, Sir."                                 â”‚
â”‚                                                                 â”‚
â”‚ JARVIS (falsch):   "Nein."                                      â”‚
â”‚ â†’ Abbruch. Wird geloggt. Nach 3 Fehlversuchen:                 â”‚
â”‚                                                                 â”‚
â”‚ JARVIS (3. Fehlversuch): "Gesperrt. Fuenfzehn Minuten."        â”‚
â”‚                                                                 â”‚
â”‚ JARVIS (kein Code gesetzt):                                     â”‚
â”‚ "Kein Code hinterlegt. Selbstprogrammierung bleibt aus."        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Schritt 3 â€” Explizite Programmier-Erlaubnis:**
Nach Code-Bestaetigung beschreibt Jarvis KONKRET was er tun will und fragt
ein letztes Mal.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ JARVIS:                                                         â”‚
â”‚ "Freitag-Routine. 18 Uhr, Licht warm, Musik. Freigabe, Sir?"    â”‚
â”‚                                                                 â”‚
â”‚ "Antwortlaenge von drei auf zwei Saetze. Freigabe?"             â”‚
â”‚                                                                 â”‚
â”‚ "Read-only auf die Energy-Entities. Kein Schreibzugriff.        â”‚
â”‚  Freigabe?"                                                     â”‚
â”‚                                                                 â”‚
â”‚ USER: "Ja" / "Mach"                                             â”‚
â”‚ JARVIS: "Erledigt, Sir."                                        â”‚
â”‚                                                                 â”‚
â”‚ USER: "Nein" / "Lass"                                           â”‚
â”‚ JARVIS: "Gut, Sir."                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Wann gilt das Protokoll?**

| Stufe | Protokoll | Begruendung |
|:-----:|:---------:|-------------|
| 13.1 Config (unkritisch) | Nur Schritt 3 (fragen ob ok) | Easter Eggs sind harmlos, kein Code noetig |
| 13.2 Automationen | Voll (Schritt 1-3) | Automationen steuern echte Geraete |
| 13.3 Tool-Generierung | Voll (Schritt 1-3) | Code-Generierung braucht maximale Kontrolle |
| 13.4 Prompt-Optimierung | Voll (Schritt 1-3) | Aendert Jarvis' eigenes Verhalten |

**Konfiguration in `settings.yaml`:**
```yaml
self_modification:
  security_code_hash: "sha256:..."   # Vorab gesetzt vom Owner
  max_failed_attempts: 3              # Danach 15 Min Sperre
  lockout_minutes: 15
  require_code_for:
    - automations       # 13.2
    - tools             # 13.3
    - prompt_patches    # 13.4
  # 13.1 (Config) braucht nur bestaetigung, keinen Code
```

**Umsetzung:**
- NEU: `self_auth.py` â€” Autorisierungsprotokoll (Code-Hash-Vergleich, Lockout, Logging)
- `brain.py`: Vor jeder Self-Mod-Aktion â†’ `self_auth.authorize()` aufrufen
- `personality.py`: Jarvis-Stil-Templates fuer Autorisierungs-Dialoge
- Fehlversuche in Redis: `mha:selfmod:failed_attempts` (TTL 15 Min)
- Audit-Log in Redis: `mha:selfmod:auth_log` (wer, wann, was, genehmigt/abgelehnt)

---

#### Sicherheitsschichten (ergaenzend zum Autorisierungsprotokoll)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                SICHERHEITSSCHICHTEN                  â”‚
â”‚                                                     â”‚
â”‚  Stufe 1: Autorisierungsprotokoll (NEU)             â”‚
â”‚  â”œâ”€ 13.1: Einfache Bestaetigung                    â”‚
â”‚  â””â”€ 13.2-13.4: Code + Beschreibung + Bestaetigung  â”‚
â”‚                                                     â”‚
â”‚  Stufe 2: Owner-Identifikation                      â”‚
â”‚  â”œâ”€ Nur Owner/Hausbesitzer darf autorisieren        â”‚
â”‚  â”œâ”€ Speaker Recognition (Phase 9.6) oder            â”‚
â”‚  â””â”€ Explizite Person-Angabe bei Text-Input          â”‚
â”‚                                                     â”‚
â”‚  Stufe 3: Whitelist / Blacklist                      â”‚
â”‚  â”œâ”€ Configs: Nur whitelisted Dateien                â”‚
â”‚  â”œâ”€ Tools: Sandbox (banned imports, max lines)       â”‚
â”‚  â”œâ”€ Automationen: Keine Sicherheits-Entities        â”‚
â”‚  â””â”€ Prompt: Kern-Identitaet geschuetzt              â”‚
â”‚                                                     â”‚
â”‚  Stufe 4: Frequenz-Limits                           â”‚
â”‚  â”œâ”€ Configs: Max 5/Tag                              â”‚
â”‚  â”œâ”€ Automationen: Max 3/Woche                       â”‚
â”‚  â”œâ”€ Tools: Max 2/Woche                              â”‚
â”‚  â””â”€ Prompt: Max 2/Woche                             â”‚
â”‚                                                     â”‚
â”‚  Stufe 5: Logging + Rollback                        â”‚
â”‚  â”œâ”€ Jede Aenderung mit Timestamp + Begruendung      â”‚
â”‚  â”œâ”€ Letzte 10 Aenderungen rollback-faehig           â”‚
â”‚  â””â”€ User kann alles einsehen + rueckgaengig machen  â”‚
â”‚                                                     â”‚
â”‚  Stufe 6: Kill-Switch                               â”‚
â”‚  â””â”€ "Jarvis, stopp Selbstprogrammierung"            â”‚
â”‚     â†’ Deaktiviert alles sofort                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Empfohlene Reihenfolge Phase 13

```
13.1 Config-Selbstmod. â”€â”€â”€â”€â”€â”€ 2 Std   â”€â”€â”€ Sicher, sofort nuetzlich
  â”‚
13.2 HA-Automationen â”€â”€â”€â”€â”€â”€â”€â”€ 4-6 Std â”€â”€â”€ Groesster Alltagsnutzen
  â”‚
13.4 Prompt-Optimierung â”€â”€â”€â”€â”€ 6-10 Std â”€â”€ Jarvis wird mit der Zeit besser
  â”‚
13.3 Tool-Generierung â”€â”€â”€â”€â”€â”€  8-12 Std â”€â”€ Maechtigste Stufe, braucht robuste Sandbox
```

**13.1 zuerst** â€” geringes Risiko, sofort spuerbar (Easter Eggs, Raum-Anpassungen).
**13.3 zuletzt** â€” braucht die meiste Sicherheitsarbeit (Sandbox).

---

### Technische Zusammenfassung Phase 13

| Modul | Aenderung |
|-------|---------|
| `function_calling.py` | Neue Tools: `edit_config`, `create_automation`, `list_my_automations` |
| `brain.py` | Self-Mod-Trigger + Autorisierungsprotokoll vor jeder Aenderung |
| `personality.py` | Laedt Prompt-Patches dynamisch + Autorisierungs-Dialog-Templates |
| NEU: `self_auth.py` | 3-Schritt-Autorisierung (Code-Abfrage, Verifizierung, Erlaubnis) |
| NEU: `self_automation.py` | Pattern â†’ Automation Pipeline |
| NEU: `tool_builder.py` | LLM-Code-Generierung + Sandbox-Validierung |
| NEU: `self_optimizer.py` | Tagesanalyse + Prompt-Patch-Vorschlaege |
| NEU: `plugins/jarvis_tools/` | Verzeichnis fuer generierte Tools |
| NEU: `config/prompt_patches/` | Prompt-Aenderungen als YAML |

**Geschaetzter Aufwand:** ~20-30 Stunden gesamt (4 Stufen)
**Voraussetzung:** Phase 6-8 sollten implementiert sein (Feedback, Memory, Patterns)

---

---

# Phase 11 â€” Jarvis Wissen & Kontext (Beyond Smart Home)
## 4 Features | Betroffene Module: brain.py, semantic_memory.py, context_builder.py
## Status: IMPLEMENTIERT (2026-02-18)

> **Ziel:** Jarvis weiss mehr als nur Smart-Home. Er kennt Rezepte, Verkehr, Wetter-Warnungen,
> deinen Kalender â€” und er lernt aus seinen Fehlern.
> **Prinzip:** 100% offline. Jarvis hat KEINEN Internetzugang. Alle externen Daten
> kommen ueber Home Assistant Entities (HA holt, Jarvis liest). Kein Cloud-LLM.

---

### Feature 11.1: Wissensdatenbank / RAG (Retrieval Augmented Generation)

**Ist-Zustand:** Wissensfragen gehen direkt an Qwen. Das Modell weiss vieles,
halluziniert aber bei spezifischen Fragen (Kochzeiten, Bedienungsanleitungen, lokale Infos).

**Soll-Zustand:**
- Lokale Wissensbasis in ChromaDB (bereits vorhanden fuer Memories):
  | Wissensbereich | Quelle | Beispiel |
  |---------------|--------|---------|
  | Kochen | Rezept-Sammlung (YAML/JSON) | "Spargel: 12-15 Min, abhaengig von Dicke" |
  | Geraete | Bedienungsanleitungen (PDF â†’ Text) | "Waschmaschine Eco-Modus: 60Â°, 2:40h" |
  | Haushalt | Alltagswissen-Sammlung | "Fenster putzen: Essig + Zeitungspapier" |
  | Persoenlich | User-eingetragene Notizen | "Allergien: Erdnuesse, Penicillin" |
- Ablauf: Frage â†’ Semantische Suche in ChromaDB â†’ Relevante Chunks + Frage an LLM
- Ehrlichkeit: "Dazu hab ich nichts gespeichert." statt halluzinieren

**Umsetzung:**
- `brain.py`: RAG-Pipeline vor LLM-Call (wenn Intent = Wissensfrage)
- `semantic_memory.py`: Neue Collection `knowledge_base` (getrennt von Personal Memories)
- NEU: `knowledge_ingester.py` â€” PDF/YAML/Text â†’ Chunks â†’ ChromaDB
- CLI-Tool: `python -m assistant.ingest /pfad/zu/docs/`

**Aufwand:** ~4-6 Stunden
**Wirkung:** HOCH â€” Jarvis wird vom Smart-Home-Butler zum Wissensassistenten.

---

### Feature 11.2: Externer Kontext via HA (Welt ausserhalb des Hauses)

**Ist-Zustand:** Jarvis kennt nur den Haus-Status. Er weiss nicht was draussen passiert
(ausser Wetter via HA Weather Entity).

**WICHTIG: Jarvis hat KEINEN Internetzugang.**
Alle externen Daten kommen ueber Home Assistant Integrationen.
HA holt die Daten aus dem Internet â†’ exponiert sie als Entities â†’ Jarvis liest die Entities.

**Soll-Zustand:**
- Jarvis liest HA-Entities die von HA-Integrationen befuellt werden:
  | HA-Integration | HA-Entity | Was Jarvis damit macht |
  |---------------|-----------|----------------------|
  | Met.no Weather | `weather.home` (existiert bereits) | Temperatur, Regen, Prognose |
  | Met.no Forecast | `weather.home` â†’ Forecast-Attribute | "Regen in 2 Stunden. Waesche reinholen." |
  | Sun Integration | `sun.sun` (existiert bereits) | Sonnenauf-/-untergang |
- Proaktive Meldungen nur bei Relevanz (nicht jede halbe Stunde Wetter)
- Kein eigener HTTP-Call, kein eigener API-Zugang â€” nur HA State API (lokal)
- Met.no liefert: Temperatur, Niederschlag, Wind, Luftdruck, Forecast (48h)

**Umsetzung:**
- `context_builder.py`: Weather/Sun-Entities in Kontext einbeziehen
- `proactive.py`: Wetter-Aenderungen als proaktive Meldung (triggered by HA Entity Change)
- Config in `settings.yaml`: Welche HA-Entities als Kontext-Quellen dienen
- **Voraussetzung:** Met.no Integration in HA (Standard-Integration, bereits vorhanden)

**Aufwand:** ~3-4 Stunden (einfacher, weil HA die Arbeit macht)
**Wirkung:** HOCH â€” "Es regnet in 20 Minuten. Waesche haengt draussen." Das ist Jarvis.

---

### Feature 11.3: Kalender-Tiefenintegration

**Ist-Zustand:** Morning Briefing (Phase 7.1) liest Kalender-Eintraege via HA.
Aber: Nur lesen, kein Verwalten, keine Konflikterkennung.

**Soll-Zustand:**
- Kalender-Management via Sprache:
  | Aktion | Beispiel |
  |--------|---------|
  | Termin erstellen | "Freitag 15 Uhr Zahnarzt" â†’ HA Calendar Event |
  | Termin verschieben | "Verschieb den Zahnarzt auf Montag" |
  | Erinnerung setzen | "Erinner mich morgen an Paket abholen" |
  | Konflikte erkennen | "Da hast du schon was um 15 Uhr." |
  | Tagesplanung | "Was steht morgen an?" â†’ Strukturierte Uebersicht |
- Integration mit HA Calendar Entities (CalDAV, Google, Local)
- Erinnerungen via `proactive.py` (30 Min vorher, konfigurierbar)

**Umsetzung:**
- `function_calling.py`: Neue Tools `create_event()`, `modify_event()`, `list_events()`
- `brain.py`: Kalender-Intent-Erkennung
- `proactive.py`: Reminder-Pipeline fuer anstehende Termine

**Aufwand:** ~4-6 Stunden
**Wirkung:** MITTEL-HOCH â€” Jarvis wird zum persoenlichen Assistenten, nicht nur Haustechnik.

---

### Feature 11.4: Korrektur-Lernen

**Ist-Zustand:** Wenn User Jarvis korrigiert ("Nein, das andere Licht!"),
wird die Korrektur nicht gespeichert. Naechstes Mal gleicher Fehler.

**Soll-Zustand:**
- Korrektur-Erkennung in der Antwort-Pipeline:
  | Trigger | Was Jarvis lernt | Speicher |
  |---------|-----------------|---------|
  | "Nein, das andere" | Entity-Praeferenz pro Raum/Kontext | Redis |
  | "Kuerzer!" | Antwortlaenge-Praeferenz | Personality Config |
  | "So nicht, eher..." | Formulierungs-Praeferenz | Few-Shot Update |
  | "Das ist falsch" | Fakten-Korrektur | Semantic Memory |
- Confirmation: "Verstanden. Wohnzimmer-Licht meint ab jetzt die Deckenlampe."
- Korrektur-History abrufbar: "Was hast du von mir gelernt?"

**Umsetzung:**
- `brain.py`: Korrektur-Intent erkennen (Negation + neue Info)
- `memory.py`: Korrektur als hochprioritaere Memory speichern (Confidence 1.0)
- `personality.py`: Korrektur-bezogene Praeferenzen anwenden

**Aufwand:** ~2-3 Stunden
**Wirkung:** SEHR HOCH â€” Jarvis macht keinen Fehler zweimal. Das definiert einen guten Butler.

---

### Technische Zusammenfassung Phase 11

| Modul | Aenderung | Status |
|-------|---------|--------|
| `brain.py` | RAG-Pipeline (_get_rag_context), Korrektur-Erkennung (_is_correction/_handle_correction), KB-Sprachbefehle | âœ… |
| NEU: `knowledge_base.py` | ChromaDB Collection mha_knowledge_base, Chunking, Ingestion, Suche | âœ… |
| `context_builder.py` | Met.no Wetter-Details (Wind, Druck, Forecast), sun.sun (Sunrise/Sunset), echte Sonnenzeiten | âœ… |
| `function_calling.py` | get_calendar_events, create_calendar_event (HA Calendar Service) | âœ… |
| `brain.py` | get_calendar_events in QUERY_TOOLS (Feedback-Loop) | âœ… |
| `settings.yaml` | knowledge_base Config (chunk_size, overlap, max_distance) | âœ… |
| `config/knowledge/` | Wissens-Verzeichnis fuer Textdateien | âœ… |

**Implementiert:** 2026-02-18, 1 Commit

---

---

# Phase 14 â€” Jarvis Wahrnehmung & Sinne
## 3 Features | Betroffene Module: brain.py, function_calling.py
## Status: Geplant

> **Ziel:** Jarvis kann SEHEN und HOEREN â€” nicht nur Text verarbeiten.
> **Hardware:** Kamera (Tuerklingel, Indoor), GPU empfohlen fuer Bildanalyse.
> **Prinzip:** 100% lokal. Kein Bild verlaesst das Netzwerk.

---

### Feature 14.1: Vision / Kamera-Integration

**Ist-Zustand:** Jarvis hat keine Augen. Kamera-Bilder liegen in HA,
werden aber nicht analysiert.

**Soll-Zustand:**
- Jarvis kann Kamera-Bilder analysieren:
  | Trigger | Was Jarvis sieht | Aktion |
  |---------|-----------------|--------|
  | Tuerklingel | Person erkannt / Paket / Unbekannter | "Paketbote. Paket abgestellt." |
  | Bewegung Garten | Tier / Person / Fahrzeug | "Katze im Garten. Wieder." |
  | Auf Anfrage | "Was siehst du vor der Tuer?" | Bildbeschreibung |
  | Zeitgesteuert | Morgens: Wetter-Check via Kamera | "Nebel. Vorsicht beim Fahren." |
- Object Detection: YOLO oder aehnliches Modell, lokal auf GPU
- Bildbeschreibung: Vision-LLM (LLaVA, Qwen-VL) fuer natuerliche Beschreibungen

**Umsetzung:**
- NEU: `vision.py` â€” Kamera-Snapshot + Object Detection + Vision-LLM
- `function_calling.py`: Neues Tool `get_camera_snapshot(camera_entity)`
- `proactive.py`: Trigger bei Tuerklingel-Event â†’ Bild analysieren â†’ Melden
- `model_router.py`: Vision-Modell neben Text-Modell verwalten
- HA Integration: `camera.snapshot` Service fuer Bild-Abruf

**Hardware:** GPU empfohlen (YOLO + Vision-LLM). CPU-Fallback moeglich aber langsam.
**Aufwand:** ~8-12 Stunden
**Wirkung:** SEHR HOCH â€” Jarvis kann SEHEN. Das aendert alles.

---

### Feature 14.2: Multi-Modal Input (Fotos & Dokumente)

**Ist-Zustand:** Jarvis versteht nur Text (Sprache via Whisper â†’ Text).

**Soll-Zustand:**
- User kann Jarvis Bilder schicken (via Companion App oder Web-Interface):
  | Was User schickt | Was Jarvis tut | Beispiel |
  |-----------------|---------------|---------|
  | Foto von Pflanze | Identifizieren | "Monstera. Alle 7 Tage giessen." |
  | Foto von Rezept | Text extrahieren + speichern | "Gespeichert unter 'Omas Gulasch'." |
  | Foto von Fehlermeldung | Diagnose | "Error 403. Zugriff verweigert. Router neustarten." |
  | Foto von Einkaufszettel | Liste erstellen | "8 Positionen erkannt. Einkaufsliste aktualisiert." |
- OCR fuer Text-Erkennung (Tesseract, lokal)
- Vision-LLM fuer Bildbeschreibung (gleich wie 14.1)

**Umsetzung:**
- `brain.py`: Multi-Modal Input Handler (Bild + Text zusammen an Vision-LLM)
- NEU: `ocr.py` â€” Tesseract-Integration fuer Text-aus-Bild
- API-Endpunkt: `/api/chat` akzeptiert `image` Parameter (Base64)
- Companion App: Foto-Upload-Button

**Aufwand:** ~6-8 Stunden
**Wirkung:** HOCH â€” Jarvis versteht die Welt, nicht nur Worte.

---

### Feature 14.3: Ambient Audio (Atmosphaere)

**Ist-Zustand:** Jarvis kann Musik abspielen und TTS ausgeben.
Aber: Keine atmosphaerische Audio-Gestaltung.

**Soll-Zustand:**
- Kontextuelle Hintergrund-Sounds ueber HA Media Player:
  | Kontext | Sound | Trigger |
  |---------|-------|---------|
  | Morgens | Vogelgezwitscher (leise) | Morning Briefing |
  | Regen draussen | Regengeraeusch drinnen | Wetter-Entity |
  | Gewitter | Kaminknistern | Wetter + Abend |
  | Einschlafen | White Noise / Naturgeraeusche | Gute-Nacht-Routine |
  | Fokus-Arbeit | Lo-Fi / Brown Noise | "Ich muss mich konzentrieren" |
- Lautstaerke: Immer unter Gespraechs-Lautstaerke (max 15%)
- Automatisch aus bei Gespraech (Jarvis hoert zu â†’ Sound pausiert)
- Deaktivierbar: "Jarvis, Stille." / Konfigurierbar in Settings

**Umsetzung:**
- NEU: `ambient.py` â€” Sound-Auswahl basierend auf Kontext + Tageszeit + Wetter
- `config/ambient_sounds/` â€” Lokale Sound-Dateien (kein Streaming, kein Internet)
- `function_calling.py`: Tool `set_ambient(mood)` / `stop_ambient()`
- Integration mit `activity.py`: Pausiert bei Interaktion

**Aufwand:** ~4-6 Stunden
**Wirkung:** MITTEL â€” Das Haus hat eine Seele, nicht nur Funktionen.

---

### Technische Zusammenfassung Phase 14

| Modul | Aenderung |
|-------|---------|
| `brain.py` | Multi-Modal Input Handler |
| `function_calling.py` | camera_snapshot, set_ambient Tools |
| `proactive.py` | Tuerklingel â†’ Vision â†’ Meldung |
| `model_router.py` | Vision-Modell verwalten |
| NEU: `vision.py` | Object Detection + Vision-LLM |
| NEU: `ocr.py` | Tesseract OCR |
| NEU: `ambient.py` | Kontextuelle Hintergrund-Sounds |

**Hardware:** GPU stark empfohlen, Kamera(s), Mikrofon
**Geschaetzter Aufwand:** ~18-26 Stunden, ~5 Commits

---

---

# Phase 15 â€” Jarvis Haushalt & Fuersorge
## 4 Features | Betroffene Module: proactive.py, context_builder.py, function_calling.py
## Status: Geplant

> **Ziel:** Jarvis kuemmert sich â€” um das Haus, die Geraete, die Gesundheit der Bewohner.
> **Prinzip:** Proaktiv aber nicht nervig. Beobachtet, meldet wenn noetig, schweigt wenn nicht.

---

### Feature 15.1: Gesundheit & Raumklima

**Ist-Zustand:** Sensoren messen CO2, Temperatur, Luftfeuchtigkeit.
Add-on hat Comfort-Score. Aber: Keine proaktiven Gesundheits-Tipps.

**Soll-Zustand:**
- Proaktive Gesundheits-Meldungen:
  | Sensor | Schwelle | Jarvis sagt |
  |--------|---------|-------------|
  | CO2 | > 1000 ppm | "CO2 Buero. Fenster." |
  | Luftfeuchtigkeit | > 70% | "Feuchtigkeit Bad hoch. Schimmelrisiko." |
  | Luftfeuchtigkeit | < 30% | "Luft trocken. Luftbefeuchter?" |
  | Temperatur | > 26Â°C Schlafzimmer | "Schlafzimmer warm. Fenster auf?" |
  | Sitzzeit | > 3h ohne Bewegung | "Drei Stunden. Kurze Pause." |
  | Hydration | Alle 2h bei Hitze | "Trink was." |
- Meldungen respektieren Stille-Matrix (nicht waehrend Meeting, nicht nachts)
- Frequenz-Limit: Max 1 Gesundheits-Tipp pro Stunde

**Umsetzung:**
- NEU: `health_monitor.py` â€” Schwellen-Ueberwachung + Hydration-Timer
- `proactive.py`: Health-Alerts in Notification-Pipeline
- `context_builder.py`: Raumklima-Daten fuer LLM-Kontext
- Schwellen konfigurierbar in `settings.yaml`

**Aufwand:** ~4-6 Stunden

---

### Feature 15.2: Einkauf & Vorrat

**Ist-Zustand:** Kein Vorrats-Tracking. Keine Einkaufsliste.

**Soll-Zustand:**
- Einkaufslisten-Management per Sprache:
  | Aktion | Beispiel |
  |--------|---------|
  | Hinzufuegen | "Milch auf die Liste" |
  | Entfernen | "Milch hab ich" |
  | Abfragen | "Was brauchen wir?" |
  | Teilen | Push an Companion App beim Einkaufen |
- Vorrats-Tracking (optional, manuell):
  - "Milch ist fast leer" â†’ Automatisch auf Liste
  - Ablaufdaten: "Joghurt laeuft morgen ab."
- Rezept-Vorschlaege basierend auf Vorrat (wenn RAG-Wissensbasis Rezepte hat)

**Umsetzung:**
- `function_calling.py`: Tools `add_to_list()`, `remove_from_list()`, `get_list()`
- HA Shopping List Integration (bereits vorhanden als Entity)
- `semantic_memory.py`: Vorrats-Collection (optional)
- `proactive.py`: Ablauf-Erinnerungen

**Aufwand:** ~3-4 Stunden (HA Shopping List existiert bereits)

---

### Feature 15.3: Geraete-Beziehung (Verschleiss & Zustand)

**Ist-Zustand:** Jarvis kennt Geraete-Zustaende (an/aus/Wert).
Kein Bewusstsein fuer Verschleiss, Alterung, ungewoehnliches Verhalten.

**Soll-Zustand:**
- Jarvis "kennt" seine Geraete und bemerkt Auffaelligkeiten:
  | Beobachtung | Jarvis sagt |
  |-------------|-------------|
  | Waschmaschine braucht laenger als ueblich | "Waschmaschine braucht 20 Min laenger als sonst." |
  | Heizung erreicht Zieltemperatur nicht | "Heizung Buero. Seit 2 Stunden auf 22 eingestellt, nur 19 erreicht." |
  | Sensor seit Tagen gleicher Wert | "Bewegungsmelder Flur. Seit 3 Tagen nichts. Batterie?" |
  | Stromverbrauch eines Geraets steigt | "Kuehlschrank verbraucht 30% mehr als letzten Monat." |
- Basiert auf historischen Durchschnittswerten (gleitender Mittelwert)
- Nicht jede Abweichung melden â€” nur signifikante (> 2x Standardabweichung)

**Umsetzung:**
- NEU: `device_health.py` â€” Geraete-Baselines berechnen + Anomalie-Erkennung
- `proactive.py`: Geraete-Anomalie als LOW-Priority-Meldung
- Redis: Baseline-Werte pro Entity (`mha:device:baseline:{entity_id}`)
- Taegliche Neuberechnung der Baselines

**Aufwand:** ~6-8 Stunden

---

### Feature 15.4: Benachrichtigungs-Intelligenz

**Ist-Zustand:** Jede proaktive Meldung wird einzeln ausgeliefert.
Niedrige und hohe Prioritaet werden gleich behandelt.

**Soll-Zustand:**
- Intelligente Notification-Pipeline:
  | Prioritaet | Verhalten | Beispiel |
  |-----------|-----------|---------|
  | KRITISCH | Sofort, laut, ggf. wiederholen | Rauchmelder, Wasseralarm |
  | HOCH | Sofort, normale Lautstaerke | Fenster offen bei Regen |
  | MITTEL | Naechste Interaktion oder in 15 Min | "Waschmaschine fertig" |
  | NIEDRIG | Batchen â€” gesammelt beim naechsten Briefing | Geraete-Anomalie, Wartung |
- Batching: Niedrige Meldungen sammeln sich â†’ "Drei Sachen: ..." beim naechsten Kontakt
- Kanal-Wahl:
  - Zu Hause â†’ TTS im richtigen Raum
  - Unterwegs â†’ Push-Notification (kurz)
  - Schlafen â†’ Nur KRITISCH, Rest morgens
- Duplikat-Erkennung: Gleiche Meldung nicht zweimal (nutzt Warning-Dedup)

**Umsetzung:**
- NEU: `notification_queue.py` â€” Priority-Queue + Batching-Logik
- `proactive.py`: Alle Meldungen durch Queue statt direkte Auslieferung
- `activity.py`: Liefert Kontext (zu Hause, schlaeft, unterwegs)
- Redis: `mha:notifications:queue` (sortiert nach Prioritaet + Timestamp)

**Aufwand:** ~3-4 Stunden

---

### Technische Zusammenfassung Phase 15

| Modul | Aenderung |
|-------|---------|
| `proactive.py` | Alle Meldungen durch Notification-Queue |
| `context_builder.py` | Raumklima-Daten erweitert |
| `function_calling.py` | Shopping-List-Tools |
| NEU: `health_monitor.py` | Raumklima + Hydration + Pausen |
| NEU: `device_health.py` | Geraete-Baselines + Anomalie-Erkennung |
| NEU: `notification_queue.py` | Priority-Queue + Batching |

**Geschaetzter Aufwand:** ~16-22 Stunden, ~6 Commits

---

---

# Phase 16 â€” Jarvis fuer Alle (Multi-User & Interface)
## 3 Features | Betroffene Module: personality.py, brain.py, Frontend
## Status: Geplant

> **Ziel:** Jarvis funktioniert nicht nur fuer den Technik-Nerd der ihn gebaut hat.
> Er erklaert sich selbst, loest Konflikte, und hat ein Gesicht.
> **Prinzip:** Jarvis ist fuer den ganzen Haushalt da.

---

### Feature 16.1: Konfliktloesung (Multi-User)

**Ist-Zustand:** Jarvis fuehrt Befehle aus â€” egal von wem.
Wenn zwei Personen verschiedene Temperaturen wollen, gewinnt der Letzte.

**Soll-Zustand:**
- Konflikterkennung + Mediation:
  | Konflikt | Jarvis | Loesung |
  |----------|--------|---------|
  | Person A: 22Â°, Person B: 20Â° | "21 Grad als Kompromiss?" | Mittelwert vorschlagen |
  | Person A: Musik laut, Person B: Ruhe | "Musik nur im Wohnzimmer. Buero bleibt still." | Raum-Isolation |
  | Person A: Licht hell, Person B: dunkel | "Stehlampe fuer dich, Decke aus fuer sie." | Zonen-Loesung |
- Praeferenz-Ranking: Owner > Mitbewohner > Gast (aus Trust-Levels)
- Bei gleichem Trust-Level: Kompromiss vorschlagen oder fragen

**Umsetzung:**
- `brain.py`: Konflikt-Detection (aktuelle Einstellung vs. neue Anfrage vs. andere Person)
- `personality.py`: Mediations-Prompts
- Nutzt Trust-Levels (bereits implementiert) fuer Priorisierung

**Aufwand:** ~3-4 Stunden

---

### Feature 16.2: Onboarding / Lernmodus

**Ist-Zustand:** Neuer Nutzer steht vor Jarvis und weiss nicht was er kann.
Kein Hilfesystem, keine Einfuehrung.

**Soll-Zustand:**
- Automatisches Onboarding fuer neue Personen:
  ```
  Neue Person erkannt (Speaker Recognition oder manuell):

  Jarvis: "Ich bin Jarvis. Ich kuemmere mich um das Haus.
  Licht, Heizung, Musik â€” sag einfach was du brauchst.
  Fuer den Anfang: 'Mach das Licht an.' Probier's."
  ```
- Auf Anfrage: "Was kannst du?" â†’ Kurzuebersicht der Faehigkeiten
- Tutorial-Modus: Jarvis erklaert bei den ersten 5 Interaktionen zusaetzlich was er tut
- "Hilfe" â†’ Kontext-sensitive Hilfe (was geht gerade im aktuellen Raum)
- Fuer Gaeste: Vereinfachte Version ohne technische Details

**Umsetzung:**
- `personality.py`: Onboarding-Prompt-Erweiterung (erste N Interaktionen ausfuehrlicher)
- `memory.py`: Flag `first_interactions_count` pro Person
- `function_calling.py`: Tool `get_capabilities()` â†’ Strukturierte Faehigkeiten-Liste
- Gaeste-Variante: Nur Basics, kein "Was kannst du alles"

**Aufwand:** ~4-6 Stunden

---

### Feature 16.3: Dashboard (Jarvis hat ein Gesicht)

**Ist-Zustand:** Jarvis existiert nur als Stimme / Text. Kein visuelles Interface
das zeigt was er denkt, tut, oder weiss.

**Soll-Zustand:**
- Web-Dashboard (React, auf vorhandenem Frontend aufbauend):
  | Bereich | Inhalt |
  |---------|--------|
  | Live-Status | Haus-Uebersicht: Temp, Licht, Anwesenheit, Energie |
  | Jarvis-Log | Letzte Entscheidungen, Aktionen, Warnungen |
  | Persoenlichkeit | Aktueller Mood, Humor-Level, Formality-Score |
  | Automationen | Von Jarvis erstellte Automationen (Phase 13.2) |
  | Wissen | Was Jarvis gelernt hat (Korrekturen, Fakten, Praeferenzen) |
  | Einstellungen | Autonomie-Level, Sarkasmus, Benachrichtigungen |
- Responsive: Tablet an der Wand / Handy / Desktop
- Optional: E-Ink Display im Flur (nur Status, minimalistisch)

**Umsetzung:**
- Add-on Frontend (React): Neue Route `/jarvis`
- API-Endpunkte: `/api/jarvis/status`, `/api/jarvis/log`, `/api/jarvis/knowledge`
- `brain.py`: Logging aller Entscheidungen fuer Dashboard
- WebSocket: Live-Updates fuer Status-Aenderungen

**Aufwand:** ~10-15 Stunden (Frontend ist Hauptaufwand)
**Wirkung:** HOCH â€” Jarvis wird greifbar. Man kann sehen was er denkt.

---

### Technische Zusammenfassung Phase 16

| Modul | Aenderung |
|-------|---------|
| `brain.py` | Konflikt-Detection, Entscheidungs-Logging |
| `personality.py` | Mediations-Prompts, Onboarding-Modus |
| `memory.py` | First-Interaction-Counter pro Person |
| `function_calling.py` | get_capabilities() Tool |
| Add-on Frontend | Dashboard Route `/jarvis` |
| Add-on API | Status/Log/Knowledge Endpunkte |

**Geschaetzter Aufwand:** ~17-25 Stunden, ~5 Commits

---

---

# GesamtÃ¼bersicht

```
                          MINDHOME JARVIS
                              â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                   â”‚                   â”‚
     ADD-ON (PC1)        ASSISTANT (PC2)     HARDWARE
     âœ… FERTIG            âœ… BASIS FERTIG     ðŸ“‹ TEILWEISE
     156 Features         14 Module           â”‚
          â”‚                   â”‚               â”œâ”€ Mikrofon/Speaker âœ…
          â”‚              â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”          â”œâ”€ Sensoren âœ…
          â”‚              â”‚ NEU:    â”‚          â”œâ”€ GPU âŒ (geplant)
          â”‚              â”‚         â”‚          â””â”€ Multi-Room âŒ
          â”‚              â”‚ Ph 6: Charakter
          â”‚              â”‚ Ph 7: Routinen
          â”‚              â”‚ Ph 8: GedÃ¤chtnis
          â”‚              â”‚ Ph 9: Stimme
          â”‚              â”‚ Ph 10: Multi-Room
          â”‚              â”‚ Ph 11: Wissen
          â”‚              â”‚ Ph 12: Authentizitaet
          â”‚              â”‚ Ph 13: Selbstprog.
          â”‚              â”‚ Ph 14: Wahrnehmung
          â”‚              â”‚ Ph 15: Fuersorge
          â”‚              â”‚ Ph 16: fuer Alle
          â”‚              â”‚         â”‚
          â”‚              â”‚ 60 neue Features
          â”‚              â”‚ ~76 Commits
          â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
     Liefert Daten an Assistant via HA API
```

## Feature-Count

| Phase | Name | Features | Commits | Status | Fokus |
|:-----:|------|:--------:|:-------:|:------:|-------|
| 6 | PersÃ¶nlichkeit | 10 | ~8 | âœ… | Charakter, Humor, Meinung |
| 7 | Routinen | 9 | ~10 | âœ… | Tagesstruktur, Szenen |
| 8 | GedÃ¤chtnis | 7 | ~10 | âœ… | Vorausdenken, Wissen |
| 9 | Stimme | 6 | ~8 | âœ… | Akustik, Erkennung |
| 10 | Multi-Room | 5 | ~8 | ðŸ†• | Praesenz, Kommunikation |
| 11 | Wissen & Kontext | 4 | ~6 | ðŸ“‹ | RAG, Kalender, Korrekturen, Extern |
| 12 | Authentizitaet | 5 | ~5 | ðŸ”§ | Few-Shot, Filter, Fine-Tuning |
| 13 | Selbstprogrammierung | 4 | ~5 | ðŸ“‹ | Config, Automationen, Tools, Prompt |
| 14 | Wahrnehmung | 3 | ~5 | ðŸ“‹ | Vision, Multi-Modal, Ambient Audio |
| 15 | Haushalt & Fuersorge | 4 | ~6 | ðŸ“‹ | Gesundheit, Einkauf, Geraete, Notifications |
| 16 | fuer Alle | 3 | ~5 | ðŸ“‹ | Konflikte, Onboarding, Dashboard |
| **Î£** | | **60** | **~76** | | |

**Gesamt: 60 neue Assistant-Features + 156 bestehende (Add-on) + 14 bestehende (Assistant) = 230 Features**

---

## Empfohlene Reihenfolge

```
Phase 6 â”€â”€â”€ PersÃ¶nlichkeit â”€â”€â”€  ~8 Commits  â”€â”€â”€ Kein neues Modul nÃ¶tig, hauptsÃ¤chlich Prompts
   â”‚
Phase 7 â”€â”€â”€ Routinen â”€â”€â”€â”€â”€â”€â”€â”€â”€  ~10 Commits â”€â”€â”€ Kann parallel zu Phase 6
   â”‚
Phase 8 â”€â”€â”€ GedÃ¤chtnis â”€â”€â”€â”€â”€â”€â”€  ~10 Commits â”€â”€â”€ 2 neue Module
   â”‚
Phase 9 â”€â”€â”€ Stimme â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ~8 Commits  â”€â”€â”€ Braucht GPU
   â”‚
Phase 10 â”€â”€ Multi-Room â”€â”€â”€â”€â”€â”€â”€  ~8 Commits  â”€â”€â”€ Braucht Wyoming Satellites
   â”‚
Phase 11 â”€â”€ Wissen â”€â”€â”€â”€â”€â”€â”€â”€â”€  ~6 Commits  â”€â”€â”€ RAG, Kalender, Korrekturen
   â”‚
Phase 12 â”€â”€ Authentizitaet â”€â”€  ~5 Commits  â”€â”€â”€ Few-Shot, Filter, ggf. Fine-Tuning
   â”‚
Phase 13 â”€â”€ Selbstprog. â”€â”€â”€â”€  ~5 Commits  â”€â”€â”€ Config, Automationen, Tools, Prompt
   â”‚
Phase 14 â”€â”€ Wahrnehmung â”€â”€â”€â”€  ~5 Commits  â”€â”€â”€ Vision, Multi-Modal (braucht GPU)
   â”‚
Phase 15 â”€â”€ Fuersorge â”€â”€â”€â”€â”€â”€  ~6 Commits  â”€â”€â”€ Gesundheit, Einkauf, Geraete
   â”‚
Phase 16 â”€â”€ fuer Alle â”€â”€â”€â”€â”€â”€  ~5 Commits  â”€â”€â”€ Konflikte, Onboarding, Dashboard
```

**Phase 12.1 + 12.3 sind der naechste Hebel** â€” unter 2 Stunden, groesster Effekt
auf die Jarvis-Authentizitaet. Few-Shot Examples + Response-Filter.

---

*Naechster Schritt: Phase 12.1 (Few-Shot Examples) + 12.3 (Response-Filter) implementieren.*
